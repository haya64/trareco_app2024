This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-12-17T18:59:01.129Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
data/
  Image_Color_test.csv
  Image_Color_train.csv
  Impression_Color.csv
program/
  Multitask_Weather-master/
    File/
      generate_tfrecord.py
      run.py
      TensorflowUtils.py
    README.md
  color.csv
  color2.csv
  colorhist.py
  colorhist2.py
  main.py
  resize.py
  Sensitivity.py
  white_df.py
program_db/
  create_table.py
  data_pandas.py
  dataaccess.py
  db.py
  delete.py
  insert_data.py
  select_data.py
  var.py
trareco_system/
  program/
    flask/
      trarecoapp/
        db/
          conect.py
          img_select.py
        static/
          css/
            style.css
        templates/
          trarecoapp/
            index.html
            result.html
            show_image.html
          layout.html
        __init__.py
        config.py
        views copy.py
        views.py
      README.md
      server.py
  SQL/
    CREATETABLE.sql
    INSERTINTO.sql
  .python-version
.gitignore
README.md

================================================================
Repository Files
================================================================

================
File: data/Image_Color_test.csv
================
,Image,Red,Blue,Green,Yellow,Purple,orange,black,Gray,white
0,asakusa.jpeg,42557,6307,22606,1179,151121,443,88786,259854,67147
1,fuziterebi.jpg,155992,0,0,8,162158,194,78221,176190,67237
2,kaihinkouen.jpg,1,5,0,2,327273,6,6857,164814,141042
3,Koukyo.jpg,71762,0,0,1987,96118,159,104882,244044,121048
4,omotesando.jpg,607,56,182,18840,183383,46,81117,219100,136669
5,skytree.jpg,19,0,0,0,329137,3,50455,231833,28553
6,teamlab.jpg,1054,83,41047,104,165249,384,124602,133750,173727
7,tocho.jpg,49497,0,0,0,185199,0,77081,194444,133779
8,tokyostation.jpg,397,68,93,123,161172,359,17374,119601,340813
9,yoyogikoen.jpg,3,0,0,96,55412,4,251605,213313,119567

================
File: data/Image_Color_train.csv
================
,Image,Red,Blue,Green,Yellow,Purple,orange,black,Gray,white
0,acuaparkshinagawa.jpg,59991,791,4,1222,204104,7823,6688,239557,119820
1,akarenga.jpg,129923,0,17,0,190333,0,69573,105204,144950
2,aoiike.jpg,108351,0,0,797,229069,0,23257,170980,107546
3,ashikaga.jpg,0,225,0,26237,178978,11,92105,138281,204163
4,desney.jpg,2359,30,21,67,157769,73,9387,133478,336816
5,desneysea.jpg,171781,216,134,39,146618,509,62315,163132,95256
6,fusimizinzya.jpg,206697,2386,0,0,136698,104641,80880,63198,45500
7,fuzisan.jpg,99124,0,0,0,203486,9823,26,60546,266995
8,ginzanonsen.jpg,142,288,736,138,167183,569,118608,178363,173973
9,hausutenbos.jpg,3098,1941,7111,15862,119777,4718,71525,165678,250290
10,houkokuji.jpg,0,0,0,12521,139287,0,120579,338975,28638
11,kawagoejinzya.jpg,271,0,0,116,100276,36,126849,148860,263592
12,kenrokuen.jpg,96927,170,579,6473,128663,146,121288,192927,92827
13,kifunejinzya.jpg,47551,849,4740,55039,166989,3061,35488,217947,108336
14,kokueihichi.jpg,19838,2,4,0,117731,12508,47221,81571,361125
15,nabananosato.jpg,4437,3800,22563,91358,132956,1467,40127,151096,192196
16,rurikouin.jpg,8243,29349,3710,2602,130399,22859,255729,142296,44813
17,skytree.jpg,79484,0,0,0,237501,1,14511,88160,220343
18,tokyotower.jpg,13765,73,1351,620,53060,317,1274,31026,538514
19,USJ.jpg,93644,328,0,6,133641,181,113418,208392,90390

================
File: data/Impression_Color.csv
================
,Sensitivity,Red,Blue,Green,Yellow,Purple,orange,black,Gray,white
0,楽しい,100,10,20,90,50,100,10,10,50
1,賑やかな,100,20,20,100,60,100,10,10,50
2,ゆっくり,10,60,90,30,20,10,80,70,50
3,気が晴れる,30,90,60,40,20,50,0,0,60
4,面白い,60,20,10,70,70,80,0,0,40
5,わいわい,80,80,0,30,70,80,0,0,60
6,はしゃぐ,90,50,0,60,0,90,10,0,60
7,のんびり,10,70,100,50,10,0,70,80,50
8,うきうき,60,60,0,40,30,80,0,0,90
9,落ち着いた,0,60,100,60,30,0,80,80,40
10,田舎,0,60,100,30,10,0,90,90,60
11,わくわく,100,30,20,90,30,100,10,10,70
12,きれい,50,90,90,90,30,50,30,30,100
13,癒される,0,90,100,60,50,10,70,70,70
14,まったり,10,10,80,40,40,0,80,80,50

================
File: program/Multitask_Weather-master/File/generate_tfrecord.py
================
#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Thu Apr  6 09:28:58 2017

@author: wzg
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from scipy import misc
import scipy.io as sio


def _bytes_feature(value):
    return tf.train.Feature(bytes_list = tf.train.BytesList(value=[value]))
    
def _int64_feature(value):
    return tf.train.Feature(int64_list = tf.train.Int64List(value=[value]))


root_path = './Data/'
tfrecords_filename = root_path + 'tfrecords/test.tfrecords'
writer = tf.python_io.TFRecordWriter(tfrecords_filename)


height = 300
width = 300
meanfile = sio.loadmat(root_path + 'mats/mean300.mat')
meanvalue = meanfile['mean'] #mean value of images in training set

txtfile = root_path + 'txt/test.txt'
fr = open(txtfile)

for i in fr.readlines():
    item = i.split()
    img = np.float64(misc.imread(root_path + '/images/test_images/' + item[0]))
    img = img - meanvalue
    maskmat = sio.loadmat(root_path + '/mats/test_mats/' + item[1])
    mask = np.float64(maskmat['seg_mask'])
    label = int(item[2])
    img_raw = img.tostring()
    mask_raw = mask.tostring()
    example = tf.train.Example(features=tf.train.Features(feature={
        'height': _int64_feature(height),
        'width': _int64_feature(width),
        'name': _bytes_feature(item[0]),
        'image_raw': _bytes_feature(img_raw),
        'mask_raw': _bytes_feature(mask_raw),
        'label': _int64_feature(label)}))
    
    writer.write(example.SerializeToString())
    
writer.close()
fr.close()

################### Test Correctness #####################################
record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)
i = 0

for string_record in record_iterator:
    if i>0:
        break
    example = tf.train.Example()
    example.ParseFromString(string_record)
    height = int(example.features.feature['height']
                                 .int64_list
                                 .value[0])
    
    width = int(example.features.feature['width']
                                .int64_list
                                .value[0])
    
    name = (example.features.feature['name']
                                  .bytes_list
                                  .value[0])
    
    img_string = (example.features.feature['image_raw']
                                  .bytes_list
                                  .value[0])
    
    mask_string = (example.features.feature['mask_raw']
                                  .bytes_list
                                  .value[0])
    
    label = (example.features.feature['label']
                                .int64_list
                                .value[0])
    
    img = np.fromstring(img_string, dtype=np.float64)
    mask = np.fromstring(mask_string, dtype=np.float64)
    reconstructed_img = img.reshape((height,width,-1))
    reconstructed_img = reconstructed_img + meanvalue
    reconstructed_mask = mask.reshape((height,width))
    
    print name
    print 'label: ' + str(label)
    plt.subplot(1,2,1)
    plt.imshow(np.uint8(reconstructed_img))
    plt.subplot(1,2,2)
    plt.imshow(np.uint8(reconstructed_mask))
    
    
    i += 1

================
File: program/Multitask_Weather-master/File/run.py
================
#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Mon May  1 17:16:14 2017

@author: wzg
"""

from __future__ import print_function
import tensorflow as tf
import numpy as np
import TensorflowUtils as utils
from six.moves import xrange
import scipy.io as sio
import scipy.misc as misc


FLAGS = tf.flags.FLAGS
tf.flags.DEFINE_integer("batch_size", "4", "batch size for training")
tf.flags.DEFINE_string("logs_dir", "logs/", "path to logs directory")
tf.flags.DEFINE_string("visualize_dir", "Data/visualize/", "path to visualzie directory")
tf.flags.DEFINE_float("learning_rate", "1e-6", "Learning rate for Adam Optimizer")
tf.flags.DEFINE_string("model_dir", "Model/", "Path to vgg model mat")
tf.flags.DEFINE_bool('debug', "False", "Debug mode: True/ False")
tf.flags.DEFINE_string('mode', "test", "Mode train/ test/ visualize")

root_path = './Data/'
train_tfrecord_filename = root_path + 'tfrecords/train.tfrecords'
test_tfrecord_filename = root_path + 'tfrecords/test.tfrecords'
MODEL_URL = 'http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat'
ckpt_path = './Model/MTV4_model.ckpt'

MAX_ITERATION = 8000
NUM_OF_CLASSESS = 6
WEATHER_CLASSES = 2
IMAGE_SIZE = 300
EPOCHS = 5
RESTORE = True

meanfile = sio.loadmat(root_path + 'mats/mean300.mat')
meanvalue = meanfile['mean']  #mean value of images in training set



def vgg_net(weights, image):
    layers = (
        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',

        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',

        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',
        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',

        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',
        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',

        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',
        'relu5_3', 'conv5_4', 'relu5_4'
    )

    net = {}
    current = image
    for i, name in enumerate(layers):
        kind = name[:4]
        if kind == 'conv':
            kernels, bias = weights[i][0][0][0][0]
            # matconvnet: weights are [width, height, in_channels, out_channels]
            # tensorflow: weights are [height, width, in_channels, out_channels]
            kernels = utils.get_variable(np.transpose(kernels, (1, 0, 2, 3)), name = name + "_w")
            bias = utils.get_variable(bias.reshape(-1), name = name + "_b")
            current = utils.conv2d_basic(current, kernels, bias)
        elif kind == 'relu':
            current = tf.nn.relu(current, name = name)
            tf.add_to_collection('activations', current)
            if FLAGS.debug:
                utils.add_activation_summary(current)
        elif kind == 'pool':
            current = utils.avg_pool_2x2(current)
        net[name] = current

    return net


def inference(image, keep_prob):
    
    print("setting up vgg initialized conv layers ...")
    model_data = utils.get_model_data(FLAGS.model_dir, MODEL_URL)

    weights = np.squeeze(model_data['layers'])

    with tf.variable_scope("inference"):
        image_net = vgg_net(weights, image)
        conv_final_layer = image_net["conv5_3"]

        pool5 = utils.max_pool_2x2(conv_final_layer)

        W6_1 = utils.weight_variable([7, 7, 512, 4096], name = "W6_1")
        b6_1 = utils.bias_variable([4096], name = "b6_1")
        conv6_1 = utils.conv2d_basic(pool5, W6_1, b6_1)
        relu6_1 = tf.nn.relu(conv6_1, name = "relu6_1")
        if FLAGS.debug:
            utils.add_activation_summary(relu6_1)
        relu_dropout6_1 = tf.nn.dropout(relu6_1, keep_prob = keep_prob)
           
  

        W7_1 = utils.weight_variable([1, 1, 4096, 4096], name = "W7_1")
        b7_1 = utils.bias_variable([4096], name = "b7_1")
        conv7_1 = utils.conv2d_basic(relu_dropout6_1, W7_1, b7_1)
        relu7_1 = tf.nn.relu(conv7_1, name = "relu7_1")
        if FLAGS.debug:
            utils.add_activation_summary(relu7_1)
        relu_dropout7_1 = tf.nn.dropout(relu7_1, keep_prob = keep_prob)
                

        W8_1 = utils.weight_variable([1, 1, 4096, NUM_OF_CLASSESS], name = "W8_1")
        b8_1 = utils.bias_variable([NUM_OF_CLASSESS], name = "b8_1")
        conv8_1 = utils.conv2d_basic(relu_dropout7_1, W8_1, b8_1)
        if FLAGS.debug:
            tf.summary.histogram("conv8_1/activation", conv8_1)
            tf.summary.scalar("conv8_1/sparsity", tf.nn.zero_fraction(conv8_1))
        

        # now to upscale to actual image size
        deconv_shape1 = image_net["pool4"].get_shape()
        W_t1 = utils.weight_variable([4, 4, deconv_shape1[3].value, NUM_OF_CLASSESS], name = "W_t1")
        b_t1 = utils.bias_variable([deconv_shape1[3].value], name = "b_t1")
        conv_t1 = utils.conv2d_transpose_strided(conv8_1, W_t1, b_t1, output_shape = tf.shape(image_net["pool4"]))
        fuse_1 = tf.add(conv_t1, image_net["pool4"], name = "fuse_1")

        if FLAGS.debug:
            tf.summary.histogram("conv_t1/activation", conv_t1)
            tf.summary.scalar("conv_t1/sparsity", tf.nn.zero_fraction(conv_t1))
            tf.summary.histogram("fuse_1/activation", fuse_1)
            tf.summary.scalar("fuse_1/sparsity", tf.nn.zero_fraction(fuse_1))

        deconv_shape2 = image_net["pool3"].get_shape()
        W_t2 = utils.weight_variable([4, 4, deconv_shape2[3].value, deconv_shape1[3].value], name = "W_t2")
        b_t2 = utils.bias_variable([deconv_shape2[3].value], name = "b_t2")
        conv_t2 = utils.conv2d_transpose_strided(fuse_1, W_t2, b_t2, output_shape = tf.shape(image_net["pool3"]))
        fuse_2 = tf.add(conv_t2, image_net["pool3"], name = "fuse_2")

        if FLAGS.debug:
            tf.summary.histogram("conv_t2/activation", conv_t2)
            tf.summary.scalar("conv_t2/sparsity", tf.nn.zero_fraction(conv_t2))
            tf.summary.histogram("fuse_2/activation", fuse_2)
            tf.summary.scalar("fuse_2/sparsity", tf.nn.zero_fraction(fuse_2))

        shape = tf.shape(image)
        deconv_shape3 = tf.stack([shape[0], shape[1], shape[2], NUM_OF_CLASSESS])
        W_t3 = utils.weight_variable([16, 16, NUM_OF_CLASSESS, deconv_shape2[3].value], name = "W_t3")
        b_t3 = utils.bias_variable([NUM_OF_CLASSESS], name = "b_t3")
        conv_t3 = utils.conv2d_transpose_strided(fuse_2, W_t3, b_t3, output_shape = deconv_shape3, stride = 8)

        annotation_pred = tf.argmax(conv_t3, axis = 3, name = "prediction")

        if FLAGS.debug:    
            tf.summary.histogram("conv_t3/activation", conv_t3)
            tf.summary.scalar("conv_t3/sparsity", tf.nn.zero_fraction(conv_t3))
            tf.summary.histogram("annotation_pred/activation", annotation_pred)
            tf.summary.scalar("annotation_pred/sparsity", tf.nn.zero_fraction(annotation_pred))
            
            
            
############################### Another branch of multi-task architecture ################################
        W6_2 = utils.weight_variable([7, 7, 512, 1024], name = "W6_2")
        b6_2 = utils.bias_variable([1024], name = "b6_2")
        conv6_2 = utils.conv2d_basic(pool5, W6_2, b6_2)
        relu6_2 = tf.nn.relu(conv6_2, name = "relu6_2")
        if FLAGS.debug:
            utils.add_activation_summary(relu6_2)
        relu_dropout6_2 = tf.nn.dropout(relu6_2, keep_prob = keep_prob)
        
        W7_2 = utils.weight_variable([1, 1, 1024, 3840], name = "W7_2")
        b7_2 = utils.bias_variable([3840], name = "b7_2")
        conv7_2 = utils.conv2d_basic(relu_dropout6_2, W7_2, b7_2)
        relu7_2 = tf.nn.relu(conv7_2, name = "relu7_2")
        if FLAGS.debug:
            utils.add_activation_summary(relu7_2)
        relu_dropout7_2 = tf.nn.dropout(relu7_2, keep_prob = keep_prob)
        
        kernel_height = conv7_2.get_shape()[1]
        kernel_width = conv7_2.get_shape()[2]
        conv7_2_gapool = tf.nn.avg_pool(relu_dropout7_2, ksize = [1, kernel_height, kernel_width, 1],
                                             strides = [1, kernel_height, kernel_width, 1], padding = "SAME")
        
        kernel_height2 = fuse_2.get_shape()[1]
        kernel_width2 = fuse_2.get_shape()[2]
        fuse_2_gapool = tf.nn.avg_pool(fuse_2, ksize=[1, kernel_height2, kernel_width2, 1],
                                       strides = [1, kernel_height2, kernel_width2, 1], padding = "SAME")
        
        concat_res = tf.concat([conv7_2_gapool, fuse_2_gapool], axis = 3)
        concat_res = tf.squeeze(concat_res)
        
        
        W8_2 = utils.weight_variable([4096, WEATHER_CLASSES], name = "W8_2")
        b8_2 = utils.bias_variable([WEATHER_CLASSES], name = "b8_2")
        logits = tf.nn.bias_add(tf.matmul(concat_res, W8_2), b8_2)
        
        
    return tf.expand_dims(annotation_pred, dim = 3), conv_t3, logits


def train(loss_val, var_list):
    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)
    grads = optimizer.compute_gradients(loss_val, var_list = var_list)
    if FLAGS.debug:
        for grad, var in grads:
            utils.add_gradient_summary(grad, var)
    return optimizer.apply_gradients(grads)



def main(argv = None):
    keep_probability = tf.placeholder(tf.float32, name = "keep_probabilty")
    image = tf.placeholder(tf.float32, shape = [None, IMAGE_SIZE, IMAGE_SIZE, 3], name = "input_image")
    annotation = tf.placeholder(tf.int32, shape = [None, IMAGE_SIZE, IMAGE_SIZE, 1], name = "annotation")
    label = tf.placeholder(tf.float32, [None, WEATHER_CLASSES], name = 'label')

    pred_annotation, logits, pred_label = inference(image, keep_probability)
    tf.summary.image("input_image", image, max_outputs = 2)
    tf.summary.image("ground_truth", tf.cast(annotation, tf.uint8), max_outputs = 2)
    tf.summary.image("pred_annotation", tf.cast(pred_annotation, tf.uint8), max_outputs = 2)

    seg_loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,
                                                                          labels=tf.squeeze(annotation, squeeze_dims = [3]),
                                                                          name = "seg_loss")))

    classification_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred_label, labels = label,
                                                                                                name = 'classification_loss'))

    regular_loss = tf.reduce_mean(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))

    total_loss = seg_loss + classification_loss + regular_loss
    
    tf.summary.scalar("seg_loss", seg_loss)
    tf.summary.scalar("classification_loss", classification_loss)
    tf.summary.scalar("total_loss", total_loss)
    
    with tf.name_scope("accuracy"):
        correct_pred = tf.equal(tf.argmax(pred_label, 1), tf.argmax(label, 1))
        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
        
    tf.summary.scalar('accuracy', accuracy)

    trainable_var = tf.trainable_variables()
    if FLAGS.debug:
        for var in trainable_var:
            utils.add_to_regularization_and_summary(var)
    train_op = train(total_loss, trainable_var)

    print("Setting up summary op...")
    summary_op = tf.summary.merge_all()
 

    print("Setting up Saver...")
    saver = tf.train.Saver()
    summary_writer = tf.summary.FileWriter(FLAGS.logs_dir, tf.get_default_graph())
    
    
    print("Setting up dataset reader")
    train_filename_queue = tf.train.string_input_producer([train_tfrecord_filename],
                                                    num_epochs=EPOCHS)
    mytrain_images, mytrain_annotations, mytrain_names, mytrain_labels = utils.read_and_decode(train_filename_queue)
    
    
    test_filename_queue = tf.train.string_input_producer([test_tfrecord_filename],
                                                    num_epochs=EPOCHS)
    mytest_images, mytest_annotations, mytest_names, mytest_labels = utils.read_and_decode(test_filename_queue, shuffle_batch=False)

    

    
    with tf.Session(graph=tf.get_default_graph()) as sess:
        init_op = tf.group(tf.global_variables_initializer(),
                               tf.local_variables_initializer())
        sess.run(init_op)
        
        if RESTORE:
            saver.restore(sess, ckpt_path)
        
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
    
        if FLAGS.mode == "train":
            for itr in xrange(MAX_ITERATION):
                #print('Iteration: %d' %itr)
                train_images, train_annotations, train_labels = sess.run([mytrain_images, mytrain_annotations, mytrain_labels])
                train_annotations = np.array(np.expand_dims(train_annotations, axis = 3))
                one_hot_labels = utils.get_one_hot_label(FLAGS.batch_size, WEATHER_CLASSES, train_labels)
                feed_dict = {image: train_images, annotation: train_annotations, label: one_hot_labels, keep_probability: 0.50}
    
                sess.run(train_op, feed_dict = feed_dict)
                
                if (itr + 1) % 2000 == 0:
                     train_acc, sum_seg_loss, sum_classification_loss, sum_total_loss = 0, 0, 0, 0
                    
                     ####### Train: 1 epoch == 2000 iteration ##################
                     for j in xrange(2000):
                         train_images, train_annotations, train_labels = sess.run([mytrain_images, mytrain_annotations, mytrain_labels])
                         train_annotations = np.array(np.expand_dims(train_annotations, axis = 3))
                         one_hot_labels = utils.get_one_hot_label(FLAGS.batch_size, WEATHER_CLASSES, train_labels)
                         feed_dict = {image: train_images, annotation: train_annotations, label: one_hot_labels, keep_probability: 1.0}
                        
                         acc, train_seg_loss, train_classification_loss, train_total_loss, \
                         summary_str = sess.run([accuracy, seg_loss, classification_loss, total_loss, summary_op], feed_dict = feed_dict)
                         summary_writer.add_summary(summary_str, itr + 1 - 2000 + j)
                        
                         train_acc += acc
                         sum_seg_loss += train_seg_loss 
                         sum_classification_loss += train_classification_loss
                         sum_total_loss += train_total_loss
                    
                     train_acc /= 2000
                     sum_seg_loss /= 2000
                     sum_classification_loss /= 2000
                     sum_total_loss /= 2000
                     print("Step: %d, Train: accuracy: %g, seg_loss: %g, classification_loss: %g, total_loss: %g" % (itr + 1, train_acc, sum_seg_loss, sum_classification_loss, sum_total_loss))
                    
                     test_acc, sum_seg_loss, sum_classification_loss, sum_total_loss = 0, 0, 0, 0
                    ######### Test: 1 epoch == 500 iteration ##################
                    
                     saver.save(sess, FLAGS.model_dir + "your_model_name.ckpt", itr)
        
        elif FLAGS.mode == "test":
            test_acc, sum_seg_loss, sum_classification_loss, sum_total_loss = 0, 0, 0, 0
            for itr in xrange(500):
                test_images, test_annotations, test_labels = sess.run([mytest_images, mytest_annotations, mytest_labels])
                test_annotations = np.array(np.expand_dims(test_annotations, axis = 3))
                one_hot_labels = utils.get_one_hot_label(FLAGS.batch_size, WEATHER_CLASSES, test_labels)
                feed_dict = {image: test_images, annotation: test_annotations, label: one_hot_labels, keep_probability: 1.0}
                
                acc, test_seg_loss, test_classification_loss, test_total_loss = \
                sess.run([accuracy, seg_loss, classification_loss, total_loss], feed_dict = feed_dict)
                
                test_acc += acc
                sum_seg_loss += test_seg_loss 
                sum_classification_loss += test_classification_loss
                sum_total_loss += test_total_loss
                    
            test_acc /= 500
            sum_seg_loss /= 500
            sum_classification_loss /= 500
            sum_total_loss /= 500
            print("Test: accuracy: %g, seg_loss: %g, classification_loss: %g, total_loss: %g" \
                  % (test_acc, sum_seg_loss, sum_classification_loss, sum_total_loss))
            
        elif FLAGS.mode == "visualize":
            for k in xrange(10):
                test_images, test_annotations = sess.run([mytest_images, mytest_annotations])
                test_annotations = np.array(np.expand_dims(test_annotations, axis = 3))
                pred = sess.run(pred_annotation, feed_dict = {image: test_images, annotation: test_annotations, keep_probability: 1.0})
                test_annotations = np.squeeze(test_annotations, axis = 3)
                pred = np.squeeze(pred, axis = 3)
        
                for itr in range(FLAGS.batch_size):
                    misc.imsave(FLAGS.visualize_dir + "img_" + str(k*FLAGS.batch_size+itr) + '.jpg', (test_images[itr] + meanvalue).astype(np.uint8))
                    sio.savemat(FLAGS.visualize_dir + 'gt_' + str(k*FLAGS.batch_size+itr) + '.mat', {'mask':test_annotations[itr].astype(np.uint8)})
                    sio.savemat(FLAGS.visualize_dir + 'pred_' + str(k*FLAGS.batch_size+itr) + '.mat', {'mask':pred[itr].astype(np.uint8)})
                    print("Saved image: %d" % (k*FLAGS.batch_size+itr))
                
        sess.close()
        coord.request_stop()
        coord.join(threads)


if __name__ == "__main__":
    tf.app.run()

================
File: program/Multitask_Weather-master/File/TensorflowUtils.py
================
import tensorflow as tf
import numpy as np
import scipy.misc as misc
import os, sys
from six.moves import urllib
import tarfile
import zipfile
import scipy.io


def get_model_data(dir_path, model_url):
    maybe_download_and_extract(dir_path, model_url)
    filename = model_url.split("/")[-1]
    filepath = os.path.join(dir_path, filename)
    if not os.path.exists(filepath):
        raise IOError("VGG Model not found!")
    data = scipy.io.loadmat(filepath)
    return data


def maybe_download_and_extract(dir_path, url_name, is_tarfile=False, is_zipfile=False):
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)
    filename = url_name.split('/')[-1]
    filepath = os.path.join(dir_path, filename)
    if not os.path.exists(filepath):
        def _progress(count, block_size, total_size):
            sys.stdout.write(
                '\r>> Downloading %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))
            sys.stdout.flush()

        filepath, _ = urllib.request.urlretrieve(url_name, filepath, reporthook=_progress)
        print()
        statinfo = os.stat(filepath)
        print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')
        if is_tarfile:
            tarfile.open(filepath, 'r:gz').extractall(dir_path)
        elif is_zipfile:
            with zipfile.ZipFile(filepath) as zf:
                zip_dir = zf.namelist()[0]
                zf.extractall(dir_path)


def save_image(image, save_dir, name, mean=None):
    """
    Save image by unprocessing if mean given else just save
    :param mean:
    :param image:
    :param save_dir:
    :param name:
    :return:
    """
    if mean:
        image = unprocess_image(image, mean)
    misc.imsave(os.path.join(save_dir, name + ".png"), image)


def get_variable(weights, name):
    init = tf.constant_initializer(weights, dtype=tf.float32)
    if name[-1] == 'w':
        var = tf.get_variable(name=name, initializer=init, regularizer=tf.contrib.layers.l2_regularizer(0.001), shape=weights.shape)
    else:
        var = tf.get_variable(name=name, initializer=init, shape=weights.shape)
    return var


def weight_variable(shape, stddev=0.02, name=None):
    if name is None:
        initial = tf.truncated_normal(shape, stddev=stddev)
        return tf.Variable(initial)
    else:
        return tf.get_variable(name=name, shape=shape, initializer=tf.contrib.layers.xavier_initializer(), regularizer=tf.contrib.layers.l2_regularizer(0.001))


def bias_variable(shape, name=None):
    initial = tf.constant(0.0, shape=shape)
    if name is None:
        return tf.Variable(initial)
    else:
        return tf.get_variable(name, initializer=initial)


def get_tensor_size(tensor):
    from operator import mul
    return reduce(mul, (d.value for d in tensor.get_shape()), 1)


def conv2d_basic(x, W, bias, mypadding='SAME'):
    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=mypadding)
    return tf.nn.bias_add(conv, bias)


def conv2d_strided(x, W, b):
    conv = tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding="SAME")
    return tf.nn.bias_add(conv, b)


def conv2d_transpose_strided(x, W, b, output_shape=None, stride = 2):
    if output_shape is None:
        output_shape = x.get_shape().as_list()
        output_shape[1] *= 2
        output_shape[2] *= 2
        output_shape[3] = W.get_shape().as_list()[2]
    
    conv = tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding="SAME")
    return tf.nn.bias_add(conv, b)


def leaky_relu(x, alpha=0.0, name=""):
    return tf.maximum(alpha * x, x, name)


def max_pool_2x2(x):
    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding="SAME")


def avg_pool_2x2(x):
    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding="SAME")


def local_response_norm(x):
    return tf.nn.lrn(x, depth_radius=5, bias=2, alpha=1e-4, beta=0.75)


def batch_norm(x, n_out, phase_train, scope='bn', decay=0.9, eps=1e-5):
    """
    Code taken from http://stackoverflow.com/a/34634291/2267819
    """
    with tf.variable_scope(scope):
        beta = tf.get_variable(name='beta', shape=[n_out], initializer=tf.constant_initializer(0.0)
                               , trainable=True)
        gamma = tf.get_variable(name='gamma', shape=[n_out], initializer=tf.random_normal_initializer(1.0, 0.02),
                                trainable=True)
        batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], name='moments')
        ema = tf.train.ExponentialMovingAverage(decay=decay)

        def mean_var_with_update():
            ema_apply_op = ema.apply([batch_mean, batch_var])
            with tf.control_dependencies([ema_apply_op]):
                return tf.identity(batch_mean), tf.identity(batch_var)

        mean, var = tf.cond(phase_train,
                            mean_var_with_update,
                            lambda: (ema.average(batch_mean), ema.average(batch_var)))
        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, eps)
    return normed


def process_image(image, mean_pixel):
    return image - mean_pixel


def unprocess_image(image, mean_pixel):
    return image + mean_pixel


def bottleneck_unit(x, out_chan1, out_chan2, down_stride=False, up_stride=False, name=None):

    def conv_transpose(tensor, out_channel, shape, strides, name=None):
        out_shape = tensor.get_shape().as_list()
        in_channel = out_shape[-1]
        kernel = weight_variable([shape, shape, out_channel, in_channel], name=name)
        shape[-1] = out_channel
        return tf.nn.conv2d_transpose(x, kernel, output_shape=out_shape, strides=[1, strides, strides, 1],
                                      padding='SAME', name='conv_transpose')

    def conv(tensor, out_chans, shape, strides, name=None):
        in_channel = tensor.get_shape().as_list()[-1]
        kernel = weight_variable([shape, shape, in_channel, out_chans], name=name)
        return tf.nn.conv2d(x, kernel, strides=[1, strides, strides, 1], padding='SAME', name='conv')

    def bn(tensor, name=None):
        """
        :param tensor: 4D tensor input
        :param name: name of the operation
        :return: local response normalized tensor - not using batch normalization :(
        """
        return tf.nn.lrn(tensor, depth_radius=5, bias=2, alpha=1e-4, beta=0.75, name=name)

    in_chans = x.get_shape().as_list()[3]

    if down_stride or up_stride:
        first_stride = 2
    else:
        first_stride = 1

    with tf.variable_scope('res%s' % name):
        if in_chans == out_chan2:
            b1 = x
        else:
            with tf.variable_scope('branch1'):
                if up_stride:
                    b1 = conv_transpose(x, out_chans=out_chan2, shape=1, strides=first_stride,
                                        name='res%s_branch1' % name)
                else:
                    b1 = conv(x, out_chans=out_chan2, shape=1, strides=first_stride, name='res%s_branch1' % name)
                b1 = bn(b1, 'bn%s_branch1' % name, 'scale%s_branch1' % name)

        with tf.variable_scope('branch2a'):
            if up_stride:
                b2 = conv_transpose(x, out_chans=out_chan1, shape=1, strides=first_stride, name='res%s_branch2a' % name)
            else:
                b2 = conv(x, out_chans=out_chan1, shape=1, strides=first_stride, name='res%s_branch2a' % name)
            b2 = bn(b2, 'bn%s_branch2a' % name, 'scale%s_branch2a' % name)
            b2 = tf.nn.relu(b2, name='relu')

        with tf.variable_scope('branch2b'):
            b2 = conv(b2, out_chans=out_chan1, shape=3, strides=1, name='res%s_branch2b' % name)
            b2 = bn(b2, 'bn%s_branch2b' % name, 'scale%s_branch2b' % name)
            b2 = tf.nn.relu(b2, name='relu')

        with tf.variable_scope('branch2c'):
            b2 = conv(b2, out_chans=out_chan2, shape=1, strides=1, name='res%s_branch2c' % name)
            b2 = bn(b2, 'bn%s_branch2c' % name, 'scale%s_branch2c' % name)

        x = b1 + b2
        return tf.nn.relu(x, name='relu')


def add_to_regularization_and_summary(var):
    if var is not None:
        tf.summary.histogram(var.op.name, var)
        tf.add_to_collection("reg_loss", tf.nn.l2_loss(var))


def add_activation_summary(var):
    if var is not None:
        tf.summary.histogram(var.op.name + "/activation", var)
        tf.summary.scalar(var.op.name + "/sparsity", tf.nn.zero_fraction(var))


def add_gradient_summary(grad, var):
    if grad is not None:
        tf.summary.histogram(var.op.name + "/gradient", grad)


################ Get one-hot label ############################################
def get_one_hot_label(batch_size, num_classes, labels):
    one_hot_labels = np.zeros((batch_size, num_classes))
    for i in range(batch_size):
        one_hot_labels[i][labels[i]] = 1

    return one_hot_labels



######################## Read data ############################################
def read_and_decode(filename_queue, shuffle_batch=True, random_noise=False):
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
      serialized_example,
      features={
          'height': tf.FixedLenFeature([], tf.int64),
          'width': tf.FixedLenFeature([], tf.int64),
          'name': tf.FixedLenFeature([], tf.string),                           
          'image_raw': tf.FixedLenFeature([], tf.string),
          'mask_raw': tf.FixedLenFeature([], tf.string),                               
          'label': tf.FixedLenFeature([], tf.int64)
      })
    
    image = tf.decode_raw(features['image_raw'], tf.float64)
    image = tf.reshape(image, [300,300,3])
    
    if random_noise:
        image = tf.image.random_brightness(image, max_delta=8)
        image = tf.image.random_contrast(image, lower=0.85, upper=1.15)
    
    mask = tf.decode_raw(features['mask_raw'], tf.float64)
    mask = tf.reshape(mask, [300,300])
    
    name = features['name']
    
    # Convert label from a scalar uint8 tensor to an int32 scalar.
    label = tf.cast(features['label'], tf.int64)
      
    
    if shuffle_batch:
        images, masks, names, labels = tf.train.shuffle_batch([image, mask, name, label],
                                                batch_size=4,
                                                capacity=4000,
                                                num_threads=2,
                                                min_after_dequeue=1000)
    else:
        images, masks, names, labels = tf.train.batch([image, mask, name, label],
                                        batch_size=4,
                                        capacity=4000,
                                        num_threads=2)
    return images, masks, names, labels

================
File: program/Multitask_Weather-master/README.md
================
# Multitask_Weather

Environment:
------------
python 2.7 <br>
tensorflow 1.4.0

Usage:
-----
1. use generate_tfrecord.py to construct tfrecord files for tensorflow
2. cd to the root path
3. change the mode in run.py (train, test and visualize)
4. python File/run.py

Dataset
------
The pretrained model and raw data used in our paper are available at [Baidu network disk](https://pan.baidu.com/s/1pMDE2uv) or [MEGA network disk.](https://mega.nz/#F!I7hWmLQQ!iq3XgDR3C1PkX7BmDvfPXw)


<br>

`Please refer to our paper for more details.`

Citation:
--------
```
@inproceedings{DBLP:conf/mm/LiWL17, 
    author   = {Xuelong Li and Zhigang Wang and Xiaoqiang Lu}, 
    title     = {A Multi-Task Framework for Weather Recognition},
    booktitle = {Proceedings of the 2017 {ACM} on Multimedia Conference, {MM} 2017, Mountain View, CA, USA, October 23-27, 2017},
    pages     = {1318--1326},
    year      = {2017}
}
```

================
File: program/color.csv
================
255, 0, 0
0, 0, 255
0, 255, 0
255, 241, 0
167, 87, 168
255, 165, 0
0, 0, 0
125, 125, 125
255, 255, 255

================
File: program/color2.csv
================
255,0,0
230,121,40
255,255,0
0,255,0
0,0,255
22,94,131
167,87,168
0,0,0
125,125,125
255,255,255

================
File: program/colorhist.py
================
import csv
from PIL import Image
import math
import sys

import Sensitivity


def rgb2hsv(r, g, b):
    # R, G, Bの値を取得して0～1の範囲内にする
    #[b, g, r] = src[y][x]/255.0
    
    # R, G, Bの値から最大値と最小値を計算
    mx = max(r, g, b)
    mn = min(r, g, b)

    # 最大値 - 最小値
    diff = mx - mn

    # Hの値を計算
    if mx == mn : h = 0
    elif mx == r : h = 60 * ((g-b)/diff)     
    elif mx == g : h = 60 * ((b-r)/diff) + 120  
    elif mx == b : h = 60 * ((r-g)/diff) + 240
    if h < 0 : h = h + 360
    
    # Sの値を計算
    if mx != 0:s = diff/mx       
    else: s = 0

    # Vの値を計算
    v = mx

    # Hを0～179, SとVを0～255の範囲の値に変換
    return h * 0.5, s * 255, v * 255

def godlove(h1, s1, v1, h2, s2, v2):
    _1 = s1*s2
    _4 = abs(h1 - h2) / 100
    _3 = math.cos(2*math.pi*_4)
    _2 = (1 - _3) 
    _5 = (abs(s1 - s2)) * (abs(s1 - s2))
    _6 = (4 * abs(v1 - v2)) * (4 * abs(v1 - v2))
    
    r = (math.trunc(_1 * _2 + _5 + _6)) / 2
    return r


args = sys.argv

# Read CSV file
f = open("/Users/haya/gdrive/Development/mirai_pj/program/color.csv", "r")
reader = csv.reader(f, delimiter=",")

color = []
for row in reader:
    color.append(row)
# print(color)


# height = 800
# weight = 800

# color_num
n = 9

imagepath_train = Sensitivity.imagepath_train()
imagepath_test = Sensitivity.imagepath_test()
# path = '/Users/haya/gdrive/Development/mirai_pj/test/asakusa.jpeg'

def color_(path):
    # Make a color histogram
    colorhist = [0] * n

    # Load an image
    img = Image.open(path)
    img = img.convert('RGB')
    # img = img.resize((height, weight))

    for x in range(800):
        for y in range(800):
            flag = 0
            idx = 0
            k = 0
            r1, g1, b1 = img.getpixel((x, y)) # 1ピクセルのRGB
            h1, s1, v1 = rgb2hsv(r1, g1, b1)

            for k in range(n):
                r2 = int(color[k][0])
                g2 = int(color[k][1])
                b2 = int(color[k][2])
                
                h2, s2, v2 = rgb2hsv(r2, g2, b2)
                
                d = godlove(h1, s1, v1, h2, s2, v2)


                if flag == 1:
                    if m > d:
                        m = d
                        idx = k
                else:
                    m = d
                    flag = 1

            colorhist[idx] = colorhist[idx] + 1

    # print(['red', 'blue', 'green', 'yellow', 'purple', 'orange', 'black', 'grey', 'white'])
    print(path, colorhist)
    return colorhist


# for p in imagepath_train:
#     p_ = '/Users/haya/gdrive/Development/mirai_pj/train/' + p
#     colorhist = color_(p_)
#     Image_Color_train = Sensitivity.colorappend(p, colorhist)

# for p in imagepath_test:
#     p_ = '/Users/haya/gdrive/Development/mirai_pj/test/' + p
#     colorhist = color_(p_)
#     Image_color_test = Sensitivity.colorappend_test(p, colorhist)

# print(Image_Color_train)
# print(Image_color_test)

Sensitivity.to_csv()

================
File: program/colorhist2.py
================
import csv
from PIL import Image
import math
import sys
import pandas as pd
import glob
import os

def rgb2hsv(r, g, b):
    # R, G, Bの値を取得して0～1の範囲内にする
    #[b, g, r] = src[y][x]/255.0
    # R, G, Bの値から最大値と最小値を計算
    mx = max(r, g, b)
    mn = min(r, g, b)

    # 最大値 - 最小値
    diff = mx - mn

    # Hの値を計算
    if mx == mn : h = 0
    elif mx == r : h = 60 * ((g-b)/diff)
    elif mx == g : h = 60 * ((b-r)/diff) + 120
    elif mx == b : h = 60 * ((r-g)/diff) + 240
    if h < 0 : h = h + 360
    # Sの値を計算
    if mx != 0:s = diff/mx
    else: s = 0

    # Vの値を計算
    v = mx

    # Hを0～179, SとVを0～255の範囲の値に変換
    return h * 0.5, s * 255, v * 255

def godlove(h1, s1, v1, h2, s2, v2):
    _1 = s1*s2
    _4 = abs(h1 - h2) / 100
    _3 = math.cos(2*math.pi*_4)
    _2 = (1 - _3) 
    _5 = (abs(s1 - s2)) * (abs(s1 - s2))
    _6 = (4 * abs(v1 - v2)) * (4 * abs(v1 - v2))
    r = (math.trunc(_1 * _2 + _5 + _6)) / 2
    return r

args = sys.argv

# Read CSV file
f = open("/Users/haya/Development/aniversity_lecture/mirai_pj/program/color2.csv", "r")
reader = csv.reader(f, delimiter=",")

color = []
for row in reader:
    color.append(row)
# print(color)


# height = 800
# weight = 800

# color_num
n = 10

def color_(path):
    # Make a color histogram
    colorhist = [0] * n

    # Load an image
    img = Image.open(path)
    # img = cv2.imread(path)
    # print("リサイズ前(高さ,幅,色)="+str(img.size))
    img = img.convert('RGB')
    # 画像の拡大・縮小（INTER_NEAREST)
    n_img = img.resize((400,600))
    # print("リサイズ後(高さ,幅,色)="+str(n_img.size))

    for x in range(400):
        for y in range(600):
            flag = 0
            idx = 0
            k = 0
            r1, g1, b1 = n_img.getpixel((x, y)) # 1ピクセルのRGB
            h1, s1, v1 = rgb2hsv(r1, g1, b1)

            for k in range(n):
                r2 = int(color[k][0])
                g2 = int(color[k][1])
                b2 = int(color[k][2])
                h2, s2, v2 = rgb2hsv(r2, g2, b2)
                d = godlove(h1, s1, v1, h2, s2, v2)


                if flag == 1:
                    if m > d:
                        m = d
                        idx = k
                else:
                    m = d
                    flag = 1

            colorhist[idx] = colorhist[idx] + 1

    # print(['red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'purple', 'black', 'gray', 'white'])
    # 色
    # print(f'\n',
    #       'red %d'%colorhist[0], '\n',
    #       'orange %d'%colorhist[1], '\n',
    #       'yellow %d'%colorhist[2], '\n',
    #       'green %d'%colorhist[3], '\n',
    #       'blue %d'%colorhist[4], '\n',
    #       'indigo %d'%colorhist[5], '\n',
    #       'purple %d'%colorhist[6], '\n',
    #       'black %d'%colorhist[7], '\n',
    #       'gray %d'%colorhist[8], '\n',
    #       'white %d'%colorhist[9], '\n',)
    # print(colorhist)
    # print(sum(colorhist))
    return colorhist

# 画像

# global_path = '/Users/haya/Development/aniversity_lecture/mirai_pj/test_pictures/'
global_path = '/Users/haya/Development/aniversity_lecture/mirai_pj/return_spot/'

# ファイル名
file_list = glob.glob(global_path+'*.*')
name_list = [os.path.basename(file) for file in file_list]

name_list = sorted(name_list)
# print(name_list) # 画像のファイル名
image_num = len(name_list)

# df

cols = ['path', 'red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'purple', 'black', 'gray', 'white']
df = pd.DataFrame(index=[], columns=cols)

record = pd.Series(['hoge', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], index=df.columns)
for _ in range(image_num):
    df = df.append(record, ignore_index=True)

x = 0
for p in name_list:
    print(x, '列')
    c = color_(global_path+p)
    c.insert(0, p)
    df.iloc[x] = c
    # print(df)
    x +=1
    # print(c)

print(df)

# excelシートに書き込み
df.to_excel('/Users/haya/Development/aniversity_lecture/mirai_pj/data/2_.xlsx', sheet_name='return_color')

================
File: program/main.py
================
from datetime import datetime
import psycopg2


dt_now = datetime.now()
dt_now_month = dt_now.month

print(dt_now_month)

# 気候学上の四季(1:春,2:夏,3:秋,4:冬)
if 3 <= dt_now_month <= 5:
    season = 1
    print('春')
elif 6 <= dt_now_month <= 8:
    season = 2
    print('夏')
elif 9 <= dt_now_month <= 11:
    season = 3
    print('秋')
else:
    season = 4
    print('冬')


'''
### 以下DBとの接続 ###

# connect postgreSQL
users = 'haya'
dbnames = 'sample'
passwords = 'Hayaki@4477'
conn = psycopg2.connect(" user=" + users +" dbname=" + dbnames +" password=" + passwords)

# excexute sql
cur = conn.cursor()
cur.execute('SELECT * FROM weather;')
results = cur.fetchall()

#output result
print(results)

cur.close()
conn.close()

'''

================
File: program/resize.py
================
import cv2
import os

path = os.getcwd() + '/Image/'

# 読み込む画像のパスを指定
path_ = "/Users/haya/Development/aniversity_lecture/mirai_pj/test_pictures/温泉_1_夏_昼.jpg"
# 読み込む画像を選択
img = cv2.imread(path_)

# リサイズ前の画像サイズ出力
print("(高さ,幅,色)="+str(img.shape))

#　リサイズするサイズ（幅、高さ）
size = (600,400)

# 画像の拡大・縮小（INTER_NEAREST)
img_inter_nearest = cv2.resize(img,size,interpolation = cv2.INTER_NEAREST)

# # リサイズ後の画像サイズ出力
print("(高さ, 幅, 色)="+str(img_inter_nearest.shape))

# 画像表示
cv2.imshow("nearest",img_inter_nearest)
cv2.waitKey(0)
cv2.destroyAllWindows()

================
File: program/Sensitivity.py
================
import pandas as pd
import numpy as np


Image_Color_train = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=0)
Image_Color_test = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=2)
Impression_Color = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=1)


# print(Image_Color)
# print(Image_Color.iloc[:,1:])

# 画像のpath
def imagepath_train():
    path = Image_Color_train.iloc[:,0].values.tolist()
    # print(path)
    return path

def imagepath_test():
    path = Image_Color_test.iloc[:,0].values.tolist()
    # print(path)
    return path


color_9 = Image_Color_train.columns[1:]
def colorappend(path, colorhist):
    # color_9 = Image_Color.columns[1:]
    # path = 'acuaparkshinagawa.jpg'
    Image_Color_train.loc[Image_Color_train[Image_Color_train['Image'] == path].index, color_9] = colorhist
    print(Image_Color_train.loc[Image_Color_train[Image_Color_train['Image'] == path].index, color_9], '\n')
    return Image_Color_train

def colorappend_test(path, colorhist):
    # color_9 = Image_Color.columns[1:]
    # path = 'acuaparkshinagawa.jpg'
    Image_Color_test.loc[Image_Color_test[Image_Color_test['Image'] == path].index, color_9] = colorhist
    print(Image_Color_test.loc[Image_Color_test[Image_Color_test['Image'] == path].index, color_9], '\n')
    return Image_Color_test

def to_csv():
    Image_Color_train.to_csv('/Users/haya/gdrive/Development/mirai_pj/data/Image_Color_train.csv', sep=',')
    Image_Color_test.to_csv('/Users/haya/gdrive/Development/mirai_pj/data/Image_Color_test.csv', sep=',')
    Impression_Color.to_csv('/Users/haya/gdrive/Development/mirai_pj/data/Impression_Color.csv', sep=',')

================
File: program/white_df.py
================
import pandas as pd
import glob
import os


cols = ['path', 'red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'purple', 'black', 'gray', 'white']
df = pd.DataFrame(index=[], columns=cols)

file_list = glob.glob('/Users/haya/Development/aniversity_lecture/mirai_pj/test_pictures/*.*')
name_list = [os.path.basename(file) for file in file_list]

name_list = sorted(name_list)
print(name_list) # 画像のファイル名
image_num = len(name_list)


record = pd.Series(['hoge', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], index=df.columns)
for _ in range(image_num):
    df = df.append(record, ignore_index=True)

x = 0
for n in name_list:
    df.iloc[x,0] = n
    x +=1

print(df)

================
File: program_db/create_table.py
================
from dataaccess import DataAccess 

# tableを作成する

da = DataAccess()

query = [
    'CREATE TABLE train_images_colors (id serial NOT NULL, path text NOT NULL, red integer NOT NULL, blue integer NOT NULL, green integer NOT NULL, yellow integer NOT NULL ,purple integer NOT NULL ,orange integer NOT NULL, black integer NOT NULL, gray integer NOT NULL, white integer NOT NULL, PRIMARY KEY(id));',
    'CREATE TABLE train_images_details (id serial NOT NULL, path text NOT NULL, name text NOT NULL, category text NOT NULL, subject text NOT NULL, time timestamp NOT NULL, location_x numeric(8, 6) NOT NULL, location_y numeric(9, 6) NOT NULL, PRIMARY KEY(id));',
    'CREATE TABLE test_images_colors (id serial NOT NULL, path text NOT NULL, red integer NOT NULL, blue integer NOT NULL, green integer NOT NULL, yellow integer NOT NULL, purple integer NOT NULL, orange integer NOT NULL, black integer NOT NULL, gray integer NOT NULL, white integer NOT NULL, PRIMARY KEY(id));',
    'CREATE TABLE test_images_details (id serial NOT NULL, path text NOT NULL, name text NOT NULL, category text NOT NULL, subject text NOT NULL, time timestamp NOT NULL, location_x numeric(8, 6) NOT NULL, location_y numeric(9, 6) NOT NULL, PRIMARY KEY(id));',
    'CREATE TABLE impressions_colors (impression text NOT NULL, red integer NOT NULL, blue integer NOT NULL, green integer NOT NULL, yellow integer NOT NULL, purple integer NOT NULL, orange integer NOT NULL, black integer NOT NULL, gray integer NOT NULL, white integer NOT NULL);',
]


if __name__ == "__main__":
    for q in query:
    	da.create_table(q)

================
File: program_db/data_pandas.py
================
from operator import index
import pandas as pd
import numpy as np


# Image_Color_train = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=0)
# Image_Color_test = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=2)
# Impression_Color = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=1,)
Image_Color_train = pd.read_csv('/Users/haya/gdrive/Development/mirai_pj/data/Image_Color_train.csv', index_col=0)
Image_Color_test = pd.read_csv('/Users/haya/gdrive/Development/mirai_pj/data/Image_Color_test.csv', index_col=0)
Impression_Color = pd.read_csv('/Users/haya/gdrive/Development/mirai_pj/data/Impression_Color.csv', index_col=0)

# print(Image_Color_train)
# print(Image_Color_test)
# print(Impression_Color)

# impressions_colors
def len_impression():
    Impression_Color = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=1,)
    len_num = len(Impression_Color.index)
    return len_num

# image_color_train, image_train_detail
def len_train():
    Image_Color_train = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=0)
    len_num = len(Image_Color_train.index)
    return len_num

# image_color_test, image_test_detail
def len_test():
    Image_Color_test = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=2)
    len_num = len(Image_Color_test.index)
    return len_num

# impressions_colors
def read_impression(num):
    Impression_Color = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=1)
    Impression_Color_record = Impression_Color.iloc[num,:].values
    return Impression_Color_record

# image_color_train
def read_train(num):
    Image_Color_train = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=0)
    Image_Color_train_record = Image_Color_train.iloc[num,:].values
    return Image_Color_train_record

# image_color_test
def read_test(num):
    Image_Color_test = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=2)
    Image_Color_test_record = Image_Color_test.iloc[num,:].values
    return Image_Color_test_record

# image_train_detail
def read_train_detail(num):
    Image_train_detail = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=3)
    Image_train_detail_record = Image_train_detail.iloc[num,:].values
    return Image_train_detail_record

# image_test_detail
def read_test_detail(num):
    Image_test_detail = pd.read_excel('/Users/haya/gdrive/Development/mirai_pj/data/miraipj.xlsx', sheet_name=4)
    Image_test_detail_record = Image_test_detail.iloc[num,:].values
    return Image_test_detail_record

def to_xlsx(Image_Color_train, Image_Color_test, Impression_Color):
    with pd.ExcelWriter('/Users/haya/gdrive/Development/mirai_pj/data/data.xlsx') as writer:
        Image_Color_train.to_excel(writer, sheet_name='Image_Color_train', index=False)
        Image_Color_test.to_excel(writer, sheet_name='Image_Color_test', index=False)
        Impression_Color.to_excel(writer, sheet_name='Impression_Color', index=False)
    
# to_xlsx(Image_Color_train, Image_Color_test, Impression_Color)

================
File: program_db/dataaccess.py
================
from var import Var
from db import DB 

class DataAccess:

	def get_users(self):
		query = "SELECT * FROM sample"
		data = ()
		db = DB(Var.hostname, Var.port, Var.dbname, Var.username, Var.password)
		return db.execute(query, data)

	def get_user_by_username(self,username):
		query = "SELECT * FROM data_user WHERE username = %s "
		data = (str(username), )
		db = DB(Var.hostname, Var.port, Var.dbname, Var.username, Var.password)
		return db.execute(query, data)

	# images_colors (train, test)
	def save_data_1(self, query, path, red, blue, green, yellow, purple, orange, black, gray, white):
		data = (str(path), int(red), int(blue), int(green), int(yellow), int(purple), int(orange), int(black), int(gray), int(white))
		db = DB(Var.hostname, Var.port, Var.dbname, Var.username, Var.password)
		return db.update(query, data)

	# images_details (train, test)
	def save_data_2(self, query, path, name, category, subject, time, location_x, location_y):
		data = (str(path), str(name), str(category), str(subject), str(time), float(location_x), float(location_y))
		db = DB(Var.hostname, Var.port, Var.dbname, Var.username, Var.password)
		return db.update(query, data)

	# impressions_colors
	def save_data_impression(self, query, impression, red, blue, green, yellow, purple, orange, black, gray, white):
		data = (str(impression), int(red), int(blue), int(green), int(yellow), int(purple), int(orange), int(black), int(gray), int(white))
		db = DB(Var.hostname, Var.port, Var.dbname, Var.username, Var.password)
		return db.update(query, data)

	def create_table(self, query):
		db = DB(Var.hostname, Var.port, Var.dbname, Var.username, Var.password)
		return db.create(query)

================
File: program_db/db.py
================
import psycopg2

class DB:

    # DONE
    def __init__(self, hostname, port, dbname, username, password):
        self.dburl = "host=" + hostname + " port=" + str(port) + " dbname=" + dbname + \
                     " user=" + username + " password=" + password

    # DONE
    def get_connection(self, dburl):
        return psycopg2.connect(self.dburl)

    # SELECT
    def execute(self, sql, data):
        conn = psycopg2.connect(self.dburl)
        cur = conn.cursor()
        if data == None:
            cur.execute(sql)
        else:
            cur.execute(sql, data)
        rows = cur.fetchall()
        cur.close()
        conn.close()
        return rows;

    # INSERT, UPDATE, DELETE, CREATE, DROP
    def update(self, sql, data):
        conn = psycopg2.connect(self.dburl)
        conn.autocommit = False
        cur = conn.cursor()
        cur.execute(sql, data)
        conn.commit()
        cur.close()
        conn.close()

    def create(self, sql):
        conn = psycopg2.connect(self.dburl)
        conn.autocommit = False
        cur = conn.cursor()
        cur.execute(sql)
        conn.commit()
        cur.close()
        conn.close()

================
File: program_db/delete.py
================
# DELETE FROM train_images_colors;

================
File: program_db/insert_data.py
================
import re
from dataaccess import DataAccess 
import data_pandas

# detaをinsertする

da = DataAccess()

# train_images_colors
query_train_1 = 'INSERT INTO train_images_colors (path, red, blue, green, yellow, purple, orange, black, gray,  white) VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);'

# train_images_details
query_train_2 = 'INSERT INTO train_images_details (path, name, category, subject, time, location_x, location_y) VALUES (%s, %s, %s, %s, %s, %s, %s);'

# test_images_colors
query_test_1 = 'INSERT INTO test_images_colors (path, red, blue, green, yellow, purple, orange, black, gray,  white) VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);'

# test_images_details
query_test_2 = 'INSERT INTO test_images_details (path, name, category, subject, time, location_x, location_y) VALUES (%s, %s, %s, %s, %s, %s, %s);'

# impressions_colors
query_impressions = 'INSERT INTO impressions_colors (impression, red, blue, green, yellow, purple, orange, black, gray, white) VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);'


# train_colors ok
"""
len_num = data_pandas.len_train()
for i in range(len_num):
    record = data_pandas.read_train(i)
    path = record[0]
    red = record[1]
    blue = record[2]
    green = record[3]
    yellow = record[4]
    purple = record[5]
    orange = record[6]
    black = record[7]
    gray = record[8]
    white = record[9]
    da.save_data_1(query_train_1, path, red, blue, green, yellow, purple, orange, black, gray, white)
"""

# train_details ok
"""
len_num = data_pandas.len_train()
for i in range(len_num):
    record = data_pandas.read_train_detail(i)
    path = record[0]
    name = record[1]
    category = record[2]
    subject = record[3]
    time = record[4]
    location_x = record[5]
    location_y = record[6]
    da.save_data_2(query_train_2, path, name, category, subject, time, location_x, location_y)
"""


# test_colors ok
"""
len_num = data_pandas.len_test()
for i in range(len_num):
    record = data_pandas.read_test(i)
    path = record[0]
    red = record[1]
    blue = record[2]
    green = record[3]
    yellow = record[4]
    purple = record[5]
    orange = record[6]
    black = record[7]
    gray = record[8]
    white = record[9]
    da.save_data_1(query_test_1, path, red, blue, green, yellow, purple, orange, black, gray, white)
"""

# test_details ok
len_num = data_pandas.len_test()
for i in range(len_num):
    record = data_pandas.read_test_detail(i)
    path = record[0]
    name = record[1]
    category = record[2]
    subject = record[3]
    time = record[4]
    location_x = record[5]
    location_y = record[6]
    da.save_data_2(query_test_2, path, name, category, subject, time, location_x, location_y)


# impressions_colors ok
"""
len_num = data_pandas.len_impression()
for i in range(len_num):
    record = data_pandas.read_impression(i)
    impression = record[0]
    red = record[1]
    blue = record[2]
    green = record[3]
    yellow = record[4]
    purple = record[5]
    orange = record[6]
    black = record[7]
    gray = record[8]
    white = record[9]
    da.save_data_impression(query_impressions, impression, red, blue, green, yellow, purple, orange, black, gray, white)
"""

================
File: program_db/select_data.py
================
from dataaccess import DataAccess 

da = DataAccess()

================
File: program_db/var.py
================
class Var:
	hostname = "localhost"
	port = "5432"
	dbname = "mirai_hoge"
	# dbname = "tourism_impressions"
	username = "haya"
	password = "hogehoge"

================
File: trareco_system/program/flask/trarecoapp/db/conect.py
================
import psycopg2

class SELECTDATA:
    def __init__(self):
        # データベース接続を初期化
        self.connection = psycopg2.connect(
            host="localhost",
            port="5432",
            database="trareco",
            user="haya",
            password=""
        )

    def select(self, columns, table, where=None):
        # カーソルを作成
        cur = self.connection.cursor()

        # クエリを指定
        if where is not None:
            query = f'SELECT {columns} FROM {table} WHERE {where}'
        else:
            query = f'SELECT {columns} FROM {table}'

        # SQLクエリを実行
        cur.execute(query)

        # 結果を取得
        result = cur.fetchall()

        # カーソルを閉じる
        cur.close()

        return result

    def select_raw(self, query):
        """
        SQL クエリを直接実行して結果を返す。

        Parameters:
            query (str): 実行するSQLクエリ。

        Returns:
            list: クエリ結果のリスト。
        """
        cur = self.connection.cursor()

        # SQLクエリを実行
        cur.execute(query)

        # 結果を取得
        result = cur.fetchall()

        # カーソルを閉じる
        cur.close()

        return result

    def close(self):
        """データベース接続を閉じる"""
        self.connection.close()

================
File: trareco_system/program/flask/trarecoapp/db/img_select.py
================
import psycopg2

# データベースに接続
conn = psycopg2.connect(
    host="localhost",
    port="5432",
    database="trareco",
    user="haya",
    password=""
)

# カーソルを作成
cur = conn.cursor()

# テーブル名と列名を指定
table_name = "tourist_area"

# 指定する画像
img = [1, 5, 10, 15, 20]

# クエリを指定
query = f'SELECT * FROM {table_name} WHERE {table_name}.tourist_id = {img[0]} OR {table_name}.tourist_id = {img[1]} OR {table_name}.tourist_id = {img[2]} OR {table_name}.tourist_id = {img[3]} OR {table_name}.tourist_id = {img[4]};'

# SQLクエリを実行
cur.execute(query)

# 結果を取得
result = cur.fetchall()

# 結果を表示
print('選択された画像')
i = 0
for row in result:
    print('選択された画像番号：', img[i])
    print(row)
    i += 1

# カーソルと接続をクローズ
cur.close()
conn.close()

================
File: trareco_system/program/flask/trarecoapp/static/css/style.css
================
.fixed-size-image {
    object-fit: cover; /* 画像がカードの大きさを超えた場合に切り取る */
}
.card-img-top {
        height: 200px; /* カードの画像の高さを統一する */
        object-fit: cover; /* 画像の縦横比を保ちながらカバー表示 */
        width: auto; /* 幅はカードの幅に合わせる */
    }

.container {
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
}


header {
    background-color: #1995ad;
}

footer {
  width: 100%;
  height: 40px; 
  text-align: center;
  padding: 40px 0;
  background-color: #a1d6e2;
}

body {
    padding-bottom: 100px;  /* footerの高さに応じて調整してください */
}

================
File: trareco_system/program/flask/trarecoapp/templates/trarecoapp/index.html
================
{% extends "layout.html" %}

{% block content %}
<div class="container mt-5">
    <!-- タイトルセクション -->
    <div class="row mb-4">
        <div class="col text-center">
            <h1 class="fw-bold">
                観光客により想像される自然景観の色彩情報と時空間情報による<br>
                観光地推薦方式
            </h1>
        </div>
    </div>

    <!-- ナビゲーションリンクセクション -->
    <div class="row">
        <div class="col text-center">
            <a href="/image" class="btn btn-primary btn-lg" role="button">観光地推薦</a>
        </div>
    </div>
</div>

{% endblock %}

================
File: trareco_system/program/flask/trarecoapp/templates/trarecoapp/result.html
================
{% extends "layout.html" %}

{% block content %}
<div class="container mt-4">
    <div class="row">
        <div class="col mx-auto">
            <!-- 感性スコアの見出し -->
            <h1 class="mb-4">あなたの感性</h1>

            <!-- 感性スコアのリスト -->
            <ul class="list-group">
                {% for mood, score in ranking %}
                <li class="list-group-item d-flex justify-content-between align-items-center">
                    {{ loop.index }}. {{ mood }}
                    <span class="badge bg-primary rounded-pill">{{ score }}</span>
                </li>
                {% endfor %}
            </ul>
        </div>
    </div>
</div>

<div class="container mt-4">
    <div class="row">
        <div class="col">
            <h1>あなたの感性に合う観光地</h1>
        </div>
    </div>
    <div class="row">
        {% for spot in recomend %}
        <div class="col-md-4">
            <div class="card mb-4 shadow-sm">
                <img src="{{ url_for('static', filename='return_images/' ~ spot.image_path) }}" alt="{{ spot.name }}"
                    class="bd-placeholder-img card-img-top" width="100%" height="225">
                <div class="card-body">
                    <h5 class="card-title">{{ loop.index }}. {{ spot.name }}</h5>
                    <p class="card-text">類似度スコア: {{ spot.score }}</p>
                    <p class="card-text">移動時間: {{ spot.travel_time_hr }} 時間</p>
                    <p class="card-text">距離: {{ spot.distance_km }} km</p>
                </div>
            </div>
        </div>
        {% endfor %}
    </div>
</div>
{% endblock %}

================
File: trareco_system/program/flask/trarecoapp/templates/trarecoapp/show_image.html
================
{% extends "layout.html" %}

{% block content %}
<POSTするために追加した class="container mt-4">
    <h1>あなたが今行きたい観光地を選んでください</h1><br>

    <h2>画像を選ぶ基準は自由です</h2>
    <form id="imageForm" action="{{ url_for('submit_selection_save') }}" method="post">
        <div class="row row-cols-1 row-cols-md-3 g-4">
            {% for image in images %}
            <div class="col">
                <div class="card h-100">
                    <img src="{{ url_for('static', filename='images/' ~ image.path) }}" alt="Image"
                        class="card-img-top img-fluid">
                    <div class="card-body text-center">
                        <div class="form-check">
                            <input class="form-check-input" type="checkbox" name="image" value="{{ image.id }}"
                                id="imageCheck{{ image.id }}">
                            <label class="form-check-label" for="imageCheck{{ image.id }}">
                                選択
                            </label>
                        </div>
                    </div>
                </div>
            </div>
            {% endfor %}
        </div>
        <div class="row mt-4">
            <div class="col text-center">
                <input type="submit" value="送信" class="btn btn-primary">
            </div>
        </div>
    </form>

    <!--POSTするために追加した-->
    <script type="text/javascript">
        document.getElementById('imageForm').addEventListener('submit', function (event) {
            event.preventDefault(); // フォームのデフォルトの送信を防ぐ

            // フォームデータを取得
            var formData = new FormData(this);

            // 選択された画像の数をカウント
            var selectedImages = formData.getAll('image').length;

            console.log("選択された画像の数:", selectedImages); // デバッグ用

            // 選択回数が3回に達した場合、submit_selectionにPOSTリクエストを送信
            if (selectedImages >= 3) {
                var redirectForm = document.createElement('form');
                redirectForm.method = 'POST';
                redirectForm.action = '{{ url_for("submit_selection") }}';

                // フォームデータを追加
                formData.forEach(function (value, key) {
                    var input = document.createElement('input');
                    input.type = 'hidden';
                    input.name = key;
                    input.value = value;
                    redirectForm.appendChild(input);
                });

                document.body.appendChild(redirectForm);
                redirectForm.submit();
            } else {
                // 通常のフォーム送信
                this.submit();
            }
        });
    </script>
    </div>
    {% endblock %}

================
File: trareco_system/program/flask/trarecoapp/templates/layout.html
================
<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <!-- css -->
    <link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='css/style.css') }}">

    <!-- js -->
    <script src="{{ url_for('static', filename='js/script.js') }}"></script>
    <title>Trareco System</title>
</head>

<body>
    <header class="mb-3">
        <nav class="navbar navbar-expand-lg navbar-light">
            <div class="container-fluid">
                <a class="navbar-brand" href="/">Trareco System</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavAltMarkup"
                    aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
                    <div class="navbar-nav">
                        <a class="nav-link active" aria-current="page" href="/">Home</a>
                        <a class="nav-link" href="image">image</a>
                        <a class="nav-link" href="#">hoge2</a>
                        <a class="nav-link disabled" href="#" tabindex="-1" aria-disabled="true">hoge3</a>
                    </div>
                </div>
            </div>
        </nav>
    </header>
    {% block content %}
    {% endblock %}
    <footer class="fixed-bottom">
        <p>© Trareco System by hayaki okada</p>
    </footer>









    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js"
        integrity="sha384-IQsoLXl5PILFhosVNubq5LC7Qb9DXgDA9i+tQ8Zj3iwWAwPtgFTxbJ8NT4GN1R8p"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.min.js"
        integrity="sha384-cVKIPhGWiC2Al4u+LWgxfKTRIcfu0JTxR+EQDz/bgldoEyl4H0zUF0QKbrJ0EcQF"
        crossorigin="anonymous"></script>

</body>

</html>

================
File: trareco_system/program/flask/trarecoapp/__init__.py
================
from flask import Flask

app = Flask(__name__)
app.config.from_object('trarecoapp.config')
app.secret_key = 'session_key'

import trarecoapp.views

================
File: trareco_system/program/flask/trarecoapp/config.py
================
DEBUG = True

================
File: trareco_system/program/flask/trarecoapp/views copy.py
================
from trarecoapp import app
from flask import render_template, request, session, redirect, url_for
from .db import conect
import random
import numpy as np
from collections import defaultdict

# セッションに使用するシークレットキーを設定
app.secret_key = 'a_random_string_with_symbols_12345!@#$%'

@app.route('/')
def index():
    # セッション情報のクリア
    session.pop('selected_images', None)
    session.pop('selection_count', None)
    
    return render_template('trarecoapp/index.html')

# 画像の表示
@app.route('/image')
def show_image():
    select = conect.SELECTDATA()
    columns = 'tourist_id, path'
    table = 'tourist_area'
    all_images = select.select(columns, table)

    # セッションに保存された画像を除外
    if 'selected_images' in session:
        all_images = [img for img in all_images if str(img[0]) not in session['selected_images']]

    selected_image = random.sample(all_images, 9) #画像枚数
    image_data = [{'id': img[0], 'path': img[1]} for img in selected_image]

    return render_template('trarecoapp/show_image.html', images=image_data)

    # images = select.select(columns, table)
    # selected_image = random.sample(images, 9) #画像枚数
    # # 画像のIDとパスを分離
    # image_data = [{'id': img[0], 'path': img[1]} for img in selected_image]
    # return render_template('trarecoapp/show_image.html', images=image_data)


#　選択された画像のIDをセッションに保存
@app.route('/submit_selection_save', methods=['POST'])
def submit_selection_save():
    selected_images = request.form.getlist('image')
    if 'selected_images' not in session:
        session['selected_images'] = selected_images
    else:
        session['selected_images'].extend(selected_images)
    
    # 選択回数をカウント
    if 'selection_count' not in session:
        session['selection_count'] = 1
    else:
        session['selection_count'] += 1

    # デバッグ用にセッション情報を出力
    print(f"選択回数: {session['selection_count']}")

    # 3回選択したらsubmit_selectionにリダイレクト
    if session['selection_count'] >= 3:
        # デバッグメッセージで選択された画像IDを全て出力
        print(f"選択された画像ID: {session['selected_images']}")
        return redirect(url_for('submit_selection'))  # submit_selectionへリダイレクト
    else:
        return redirect(url_for('show_image'))




# 内積計算とソートを行う関数
def calculate_similarity(input_vector, mood_vectors):
    # 入力ベクトルのNumPy配列
    input_array = np.array(input_vector)

    # 結果を保存するリスト
    similarity_scores = []

    # 各感性ベクトルとの内積を計算
    for mood_vector in mood_vectors:
        mood_id, mood_name, *mood_values = mood_vector
        mood_array = np.array(mood_values)
        similarity = np.dot(input_array, mood_array)
        similarity_scores.append((mood_name, similarity))
    return similarity_scores


# ユーザーの感性と観光地の類似度を求める関数
def recommend_spot(user_vectors):
    # レコメンド観光地を取得
    select = conect.SELECTDATA()
    columns = '*'
    table = 'return_tourist_area'
    tourist_spots = select.select(columns, table)

    # レコメンド観光地の色彩を取得
    columns = '*'
    table = 'return_colorhistgram'
    tourist_colors = select.select(columns, table)

    # 感性と色彩の対応表を取得
    columns = '*'
    table = 'color2imp'
    sensibility_weights = select.select(columns, table)

    # 色彩と感性のスコア計算
    sensibility_scores = {}
    sensibility_scores = defaultdict(dict)
    for colors in tourist_colors:
        tourist_id = colors[0]
        for sensibility in sensibility_weights:
            sensibility_name = sensibility[1]
            weights = sensibility[2:]
            score = sum(c * w for c, w in zip(colors[2:], weights))
            sensibility_scores[tourist_id][sensibility_name] = score

    # デバッグ用出力
    print(f"sensibility_scores: {sensibility_scores}")

    # 類似度計算
    similarity_scores = {}
    print(f"user_vectors: {user_vectors}")  # デバッグ用出力

    for tourist_id, scores in sensibility_scores.items():
        similarity = 0
        for sensibility, user_score in user_vectors:
            similarity += user_score * scores.get(sensibility, 0)
        similarity_scores[tourist_id] = similarity

        # デバッグ用出力
        print(f"観光地ID: {tourist_id}, 類似度スコア: {similarity}")   

    # 最終ランキングの生成
    sorted_scores = sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True)

    # ランキング結果をリスト形式で作成
    ranking_results = []
    for tourist_id, score in sorted_scores:
        spot_info = next(spot for spot in tourist_spots if spot[0] == tourist_id)
        spot_name = spot_info[2]
        image_path = spot_info[1]
        ranking_results.append([spot_name, image_path, score])

    # デバッグ用出力
    print(f"ランキング結果: {ranking_results}")

    return ranking_results




# 選択された画像IDから感性を推定し、観光地を推薦
@app.route('/submit_selection', methods=['GET','POST'])
def submit_selection():

    # 選択した画像の色彩を抽出
    selected_image_ids = request.form.getlist('image')
    print(f"selected_image_ids: {selected_image_ids}")  # デバッグ用出力

    color_lists = [] # 入力ベクトル

    select = conect.SELECTDATA()
    columns = '*'
    table = 'colorhistgram'
    for id in selected_image_ids:
        where = f'tourist_id = {id}'
        colors = select.select(columns, table, where)
        colors = colors[0][1:]
        color_lists.append(colors)

    # 感性と色彩の対応表を取得
    select = conect.SELECTDATA()
    columns = '*'
    table = 'color2imp'
    col2imp = select.select(columns, table) # 感性ベクトル

    
    
    
    print('color_list', color_lists)
    print('col2imp', col2imp)

    total_scores = {}
    for color_list in color_lists:
        for mood, score in calculate_similarity(color_list, col2imp):
            if mood not in total_scores:
                total_scores[mood] = 0
            total_scores[mood] += score

    # 総類似度ランキング
    sorted_total_scores = sorted(total_scores.items(), key=lambda x: x[1], reverse=True)

    print("最終的な類似度ランキング:")
    for mood, score in sorted_total_scores:
        print(f"{mood}: {score}")

    
    recommend_spots = recommend_spot(sorted_total_scores)
    print(recommend_spots)


    return render_template('trarecoapp/ranking.html', ranking=sorted_total_scores, recomend=recommend_spots)

================
File: trareco_system/program/flask/trarecoapp/views.py
================
from trarecoapp import app
from flask import render_template, request, session, redirect, url_for
from flask_session import Session
from .db import conect
import random
import numpy as np
from collections import defaultdict
import math


# セッションに使用するシークレットキーを設定
app.secret_key = 'a_random_string_with_symbols_12345!@#$%'

# セッションの設定
app.config['SESSION_TYPE'] = 'filesystem'
Session(app)

@app.route('/')
def index():
    # セッション情報のクリア
    session.pop('selected_images', None)
    session.pop('selection_count', None)

    # デバッグ用メッセージを出力
    print("=== 新しいセッションがスタートしました ===")
    
    return render_template('trarecoapp/index.html')

# 画像の表示
@app.route('/image')
def show_image():
    select = conect.SELECTDATA()
    columns = 'tourist_id, path'
    table = 'tourist_area'
    all_images = select.select(columns, table)

    if 'selected_images' in session:
        # 選択済み画像を除外
        all_images = [img for img in all_images if str(img[0]) not in session['selected_images']]

    # エラー処理: 残り画像が9枚未満の場合
    if len(all_images) < 9:
        print("画像が不足しています")
        return "エラー: 利用可能な画像が不足しています", 500

    # ランダムに9枚選択
    selected_image = random.sample(all_images, 9)
    image_data = [{'id': img[0], 'path': img[1]} for img in selected_image]

    return render_template('trarecoapp/show_image.html', images=image_data)


#　選択された画像のIDをセッションに保存
@app.route('/submit_selection_save', methods=['POST'])
def submit_selection_save():
    selected_images = request.form.getlist('image')

    print(f"POSTデータ: {request.form}")  # POSTデータを確認
    print(f"選択された画像: {selected_images}")  # デバッグ用
    print(f"セッション: {session}")  # セッション全体を確認


    if 'selected_images' not in session:
        session['selected_images'] = selected_images
    else:
        session['selected_images'].extend(selected_images)
    
    # 選択回数をカウント
    if 'selection_count' not in session:
        session['selection_count'] = 1
    else:
        session['selection_count'] += 1

    # デバッグ用にセッション情報を出力
    print(f"選択回数: {session['selection_count']}")

    # 3回選択したらsubmit_selectionにリダイレクト
    if session['selection_count'] >= 3:
        selected_images_html = ''.join(
            f'<input type="hidden" name="image" value="{image}">' for image in session['selected_images']
        )
        return f'''
        <form id="redirectForm" method="POST" action="/submit_selection">
            {selected_images_html}
        </form>
        <script type="text/javascript">
            document.getElementById("redirectForm").submit();
        </script>
        '''
    else:
        return redirect(url_for('show_image'))
    


@app.route('/submit_selection', methods=['GET', 'POST'])
def submit_selection():
    if request.method == 'POST' or 'selected_images' in session:
        # セッションまたはリクエストから選択された画像のIDを取得
        selected_image_ids = session.get('selected_images', [])
        if not selected_image_ids:
            selected_image_ids = request.form.getlist('image')
        
        if not selected_image_ids:
            print("No images selected")
            return redirect(url_for('index'))
        
        print(f"selected_image_ids: {selected_image_ids}")  # デバッグ用出力

        # SELECTDATA インスタンスを作成
        select = conect.SELECTDATA()

        try:
            # 混雑度の平均値を計算して保存
            average_crowding = calculate_average_crowding(selected_image_ids, select)
            session['average_crowding'] = average_crowding
            print(f"最終セッション内の平均混雑度: {average_crowding}")

            # 天気を判定して保存
            weather_id = determine_weather(selected_image_ids, select)
            session['weather_id'] = weather_id
            print(f"判定された天気ID: {weather_id}")

            # 時間帯を判定
            timezone_id = determine_timezone(selected_image_ids, select)
            session['timezone_id'] = timezone_id
            print(f"判定された時間帯ID: {timezone_id}")
            
            # 色彩ヒストグラムのデータを取得
            color_lists = []
            for image_id in selected_image_ids:
                where = f'tourist_id = {image_id}'
                colors = select.select('*', 'colorhistgram', where)
                if colors:
                    color_lists.append(colors[0][1:])  # ID列を除く
                else:
                    print(f"No colors found for tourist_id: {image_id}")

            # 総合色彩ヒストグラムを生成
            total_histogram = [sum(color) for color in zip(*color_lists)]
            print(f"総合ヒストグラム: {total_histogram}")

            # 正規化
            total_pixels = sum(total_histogram)
            normalized_histogram = [
                value / total_pixels for value in total_histogram
            ] if total_pixels > 0 else total_histogram
            print(f"正規化されたヒストグラム: {normalized_histogram}")

            # 感性と色彩の対応表を取得
            col2imp = select.select('*', 'color2imp')
            print(f"感性と色彩の対応表: {col2imp}")

            # 感性スコアの計算
            mood_scores = calculate_color_to_mood_similarity(normalized_histogram, col2imp)
            sorted_total_scores = sorted(mood_scores.items(), key=lambda x: x[1], reverse=True)
            print("最終的な感性ランキング:")
            for mood, score in sorted_total_scores:
                print(f"{mood}: {score}")

            # 推薦観光地を取得（修正: average_crowding を渡す）
            recommend_spots = recommend_spot(sorted_total_scores, average_crowding, weather_id, timezone_id)
            print(f"推薦観光地: {recommend_spots}")


            return render_template('trarecoapp/result.html', ranking=sorted_total_scores, recomend=recommend_spots)

        finally:
            # SELECTDATA の接続をクローズ
            select.close()

    else:
        return redirect(url_for('index'))


# 推薦観光地のランキングを生成
def recommend_spot(
    sorted_total_scores,
    average_crowding,
    weather_id,
    timezone_id,
    user_lat=35.681236,  # デフォルト値: 東京駅の緯度
    user_lon=139.767125, # デフォルト値: 東京駅の経度
    speed_kmh=60         # デフォルト値: 60km/h
):
    """
    観光地の推薦リストを作成し、混雑度・天気・時間帯・移動時間を考慮。

    Parameters:
        sorted_total_scores (list): ユーザーの感性ベクトルランキング。
        average_crowding (float): ユーザーが選択した画像の平均混雑度。
        weather_id (int): 判定された天気ID。
        timezone_id (int): 判定された時間帯ID。
        user_lat (float): ユーザーの緯度（デフォルト: 東京駅）。
        user_lon (float): ユーザーの経度（デフォルト: 東京駅）。
        speed_kmh (float): 移動速度（km/h、デフォルト: 60）。

    Returns:
        list: 推薦観光地のランキング結果。
    """
    select = conect.SELECTDATA()
    try:
        # 観光地情報を取得
        columns = 'r_tourist_id, r_path, r_area_name, r_longitude, r_latitude, r_season_id, r_timezone_id, r_category_id, r_crowding, r_weather'
        table = 'return_tourist_area'
        tourist_spots = select.select(columns, table)

        if not tourist_spots:
            print("No tourist spots found in the database.")
            return []

        # 観光地情報を辞書形式に変換
        tourist_dict = {spot[0]: spot for spot in tourist_spots}

        # 色彩データを一括取得
        color_histogram_data = select.select('*', 'return_colorhistgram')
        color_dict = {row[0]: row[1:] for row in color_histogram_data}

        # 感性ベクトルを取得
        mood_vectors = select.select('*', 'color2imp')

        # ユーザーの感性ベクトル
        user_mood_vector = {mood: score for mood, score in sorted_total_scores}

        # 各観光地の感性ベクトルと類似度を計算
        similarity_scores = {}
        for tourist_id, spot_info in tourist_dict.items():
            if tourist_id not in color_dict:
                print(f"No color data found for r_tourist_id: {tourist_id}")
                continue

            color_vector = color_dict[tourist_id]
            spot_mood_vector = calculate_color_to_mood_similarity(color_vector, mood_vectors)

            similarity_score = calculate_user_to_spot_similarity(
                user_mood_vector, spot_mood_vector, spot_info[2]
            )
            similarity_scores[tourist_id] = similarity_score

        # 類似度スコアを降順にソート
        sorted_scores = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)

        # ランキング結果を作成
        ranking_results = [
            {
                'id': tourist_dict[tourist_id][0],
                'name': tourist_dict[tourist_id][2],
                'image_path': tourist_dict[tourist_id][1],
                'longitude': tourist_dict[tourist_id][3],
                'latitude': tourist_dict[tourist_id][4],
                'crowding': tourist_dict[tourist_id][8],  # 混雑度
                'weather': tourist_dict[tourist_id][9],   # 天気ID
                'timezone': tourist_dict[tourist_id][6], # 時間帯ID
                'score': score
            }
            for tourist_id, score in sorted_scores
        ]

        print(f"ランキング結果: {len(ranking_results)} 件生成")

        # 混雑度による絞り込みを実行
        filtered_results = filter_recommendations_by_crowding(ranking_results, average_crowding)

        # 天気による絞り込みを実行
        filtered_results = filter_recommendations_by_weather(filtered_results, weather_id)

        # 時間帯による絞り込みを実行
        filtered_results = filter_recommendations_by_timezone(filtered_results, timezone_id)

        # 移動時間の計算を実行
        final_results = calculate_travel_time((user_lat, user_lon), filtered_results, speed_kmh)

        # デバッグ用に移動時間を出力
        # デバッグ用に移動時間を出力
        print("=== 絞り込まれた観光地とその詳細情報 ===")
        for spot in final_results:
            print(f"観光地名: {spot['name']}")
            print(f"画像パス: {spot['image_path']}")
            print(f"緯度: {spot['latitude']}, 経度: {spot['longitude']}")
            print(f"混雑度: {spot['crowding']}")
            print(f"天気ID: {spot['weather']}")
            print(f"時間帯ID: {spot['timezone']}")
            print(f"類似度スコア: {spot['score']:.2f}")
            print(f"距離: {spot['distance_km']} km")
            print(f"移動時間: {spot['travel_time_hr']} 時間")
            print("-" * 40)


        return final_results

    except Exception as e:
        print(f"エラーが発生しました: {e}")
        return []



def calculate_color_to_mood_similarity(color_vector, mood_vectors):
    """
    総合色彩ヒストグラムと色彩と感性語の対応行列を用いて感性ベクトルを生成し、スコアを1以下に正規化。

    Parameters:
        color_vector (list): 正規化された総合色彩ヒストグラム Hₛ。
        mood_vectors (list): 感性データのベクトルリスト [(id, name, *values)]。

    Returns:
        dict: 感性名とスコアの辞書（スコアは1以下に正規化）。
    """
    # 感性スコアを格納する辞書
    mood_scores = {}

    # ヒストグラムを numpy 配列に変換
    histogram = np.array(color_vector)

    # 感性スコアの計算
    for mood_vector in mood_vectors:
        mood_id, mood_name, *mood_weights = mood_vector
        weights = np.array(mood_weights)

        # cₙ = Σ Hₛ(m) * Aₘₙ
        mood_score = np.dot(histogram, weights)

        # 感性名をキーにスコアを格納
        mood_scores[mood_name] = mood_score

    # スコアを1以下に正規化
    total_score = sum(mood_scores.values())
    if total_score > 0:
        mood_scores = {k: v / total_score for k, v in mood_scores.items()}

    return mood_scores


# ユーザー感性ベクトルと観光地感性ベクトルの類似度を測る関数
def calculate_user_to_spot_similarity(user_mood_vector, spot_mood_vector, spot_name='unknown spot'):
    """
    ユーザー感性ベクトルと観光地感性ベクトルの類似度をユークリッド距離で計算。

    Parameters:
        user_mood_vector (dict): ユーザー感性ベクトル（感性名とスコアの辞書）。
        spot_mood_vector (dict): 観光地感性ベクトル（感性名とスコアの辞書）。
        spot_name (str): 観光地名（デバッグ用）。

    Returns:
        float: 類似度スコア（ユークリッド距離を使用）。
    """
    # 共通の感性を使用してベクトル化
    common_keys = set(user_mood_vector.keys()) & set(spot_mood_vector.keys())
    user_array = np.array([user_mood_vector[key] for key in common_keys])
    spot_array = np.array([spot_mood_vector[key] for key in common_keys])

    # デバッグ用出力
    print("=== デバッグ: 感性ベクトル比較 ===")
    print(f"観光地: {spot_name}")
    print(f"ユーザー感性ベクトル (共通): {user_array}")
    print(f"観光地感性ベクトル (共通): {spot_array}")
    print(f"共通の感性キー: {common_keys}")

    # ユークリッド距離の計算
    distance = np.sqrt(np.sum((user_array - spot_array) ** 2))

    # 類似度として距離を返す
    similarity = -distance  # 小さい距離を大きいスコアとして扱う

    # デバッグ用出力
    print(f"計算されたユークリッド距離: {distance}")
    print(f"類似度スコア (負の距離): {similarity}")
    print("================================")

    return similarity


def calculate_average_crowding(selected_image_ids, db_connection):
    """
    選択された画像の混雑度平均を計算し保存。

    Parameters:
        selected_image_ids (list): ユーザーが選択した画像のIDリスト。
        db_connection (object): データベース接続オブジェクト。

    Returns:
        float: 選択された画像の平均混雑度。
    """
    total_crowding = 0.0
    for image_id in selected_image_ids:
        # データベースから混雑度を取得
        where = f'tourist_id = {image_id}'  # 修正
        columns = 'crowding'
        table = 'tourist_area'
        result = db_connection.select(columns, table, where)

        if result and result[0][0] is not None:
            total_crowding += float(result[0][0])  # 混雑度を累積

    # 平均混雑度を計算
    average_crowding = total_crowding / len(selected_image_ids) if selected_image_ids else 0.0
    print(f"計算された平均混雑度: {average_crowding}")
    return average_crowding


def determine_weather(selected_image_ids, db_connection):
    """
    選択された画像の天気を判定。

    Parameters:
        selected_image_ids (list): ユーザーが選択した画像のIDリスト。
        db_connection (object): データベース接続オブジェクト。

    Returns:
        int: 判定された天気ID。または、条件を満たさない場合は None。
    """
    ids = ','.join(map(str, selected_image_ids))
    query = f"""
        SELECT weather, COUNT(*)
        FROM tourist_area
        WHERE tourist_id IN ({ids})
        GROUP BY weather
    """
    result = db_connection.select_raw(query)

    weather_counts = {row[0]: row[1] for row in result}
    total_images = sum(weather_counts.values())

    print(f"天気の出現数: {weather_counts}, 総画像数: {total_images}")  # デバッグ用

    threshold = 0.5
    for weather_id, count in weather_counts.items():
        if count / total_images > threshold:
            print(f"最終的に判定された天気ID: {weather_id}")
            return weather_id

    print("最終的に判定された天気ID: None")
    return None



def determine_timezone(selected_image_ids, db_connection):
    """
    選択された画像の時間帯を判定。

    Parameters:
        selected_image_ids (list): ユーザーが選択した画像のIDリスト。
        db_connection (object): データベース接続オブジェクト。

    Returns:
        int: 判定された時間帯ID。または、条件を満たさない場合は None。
    """
    ids = ','.join(map(str, selected_image_ids))
    query = f"""
        SELECT timezone_id, COUNT(*)
        FROM tourist_area
        WHERE tourist_id IN ({ids})
        GROUP BY timezone_id
    """
    result = db_connection.select_raw(query)

    timezone_counts = {row[0]: row[1] for row in result}
    total_images = sum(timezone_counts.values())

    print(f"時間帯の出現数: {timezone_counts}, 総画像数: {total_images}")  # デバッグ用

    threshold = 0.75
    for timezone_id, count in timezone_counts.items():
        if count / total_images > threshold:
            print(f"最終的に判定された時間帯ID: {timezone_id}")
            return timezone_id

    print("最終的に判定された時間帯ID: None")
    return None


def filter_recommendations_by_crowding(recommendation_spots, average_crowding):
    """
    混雑度に基づいて推薦観光地を絞り込む。

    Parameters:
        recommendation_spots (list): 推薦観光地情報のリスト（各観光地は辞書形式）。
        average_crowding (float): ユーザーが選択した画像の平均混雑度。

    Returns:
        list: 混雑度条件を満たす推薦観光地リスト。
    """
    Tco = 0.02  # 混雑度の閾値

    # 混雑を許容するかどうかを判定
    allow_crowding = average_crowding > Tco
    print(f"混雑許容判定: {'許容する' if allow_crowding else '許容しない'} (平均混雑度: {average_crowding})")

    filtered_spots = []

    for spot in recommendation_spots:
        crowding = spot.get('crowding', 0.0)  # 推薦観光地の混雑度を取得

        if allow_crowding:
            # 混雑を許容する場合、すべての観光地を含める
            filtered_spots.append(spot)
        else:
            # 混雑を許容しない場合、混雑度が閾値以下の観光地を含める
            if crowding <= Tco:
                filtered_spots.append(spot)

    # デバッグ用出力
    print(f"混雑度絞り込み後の推薦観光地数: {len(filtered_spots)} / {len(recommendation_spots)}")
    return filtered_spots

def filter_recommendations_by_weather(recommendations, weather_id):
    """
    天気条件に基づいて推薦観光地を絞り込む。

    Parameters:
        recommendations (list): 推薦観光地リスト。
        weather_id (int): 判定された天気ID。Noneの場合、絞り込みを行わない。

    Returns:
        list: 絞り込み後の推薦観光地リスト。
    """
    if weather_id is None:
        print("天気条件による絞り込みを行いません（任意の天気）。")
        return recommendations  # 絞り込みなし

    # 絞り込み処理
    filtered = [spot for spot in recommendations if spot['weather'] == weather_id]

    print(f"天気条件（ID: {weather_id}）による絞り込み後の推薦観光地数: {len(filtered)} / {len(recommendations)}")
    return filtered

def filter_recommendations_by_timezone(recommendations, timezone_id):
    """
    時間帯条件に基づいて推薦観光地を絞り込む。

    Parameters:
        recommendations (list): 推薦観光地リスト。
        timezone_id (int): 判定された時間帯ID。Noneの場合、絞り込みを行わない。

    Returns:
        list: 絞り込み後の推薦観光地リスト。
    """
    if timezone_id is None:
        print("時間帯条件による絞り込みを行いません（任意の時間帯）。")
        return recommendations  # 絞り込みなし

    # 絞り込み処理
    filtered = [spot for spot in recommendations if spot['timezone'] == timezone_id]

    print(f"時間帯条件（ID: {timezone_id}）による絞り込み後の推薦観光地数: {len(filtered)} / {len(recommendations)}")
    return filtered

# 移動時間計算
def calculate_travel_time(user_location, tourist_spots, speed_kmh=60):
    """
    観光地との移動時間を計算。

    Parameters:
        user_location (tuple): ユーザーの現在地 (latitude, longitude)。
        tourist_spots (list of dict): 観光地情報のリスト。各観光地は辞書形式で含む (id, name, latitude, longitude, ...)。
        speed_kmh (float): 移動速度 (km/h)。

    Returns:
        list: 観光地情報に移動時間と距離を追加したリスト。
    """
    R = 6371  # 地球の半径 (km)
    user_lat, user_lon = map(float, user_location)  # 緯度・経度をfloat型に変換
    user_lat_rad = math.radians(user_lat)
    user_lon_rad = math.radians(user_lon)

    results = []
    for spot in tourist_spots:
        try:
            # 緯度・経度の取得と変換
            spot_lat = float(spot['latitude'])
            spot_lon = float(spot['longitude'])
            spot_lat_rad = math.radians(spot_lat)
            spot_lon_rad = math.radians(spot_lon)

            # 緯度・経度の差を計算
            delta_lat = spot_lat_rad - user_lat_rad
            delta_lon = spot_lon_rad - user_lon_rad

            # 大円距離を計算
            a = (math.sin(delta_lat / 2) ** 2 +
                 math.cos(user_lat_rad) * math.cos(spot_lat_rad) * math.sin(delta_lon / 2) ** 2)
            c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
            distance = R * c  # 距離 (km)

            # 移動時間を計算
            travel_time = distance / speed_kmh  # 時間 (h)

            # 結果をリストに追加
            results.append({
                **spot,
                'distance_km': round(distance, 2),
                'travel_time_hr': round(travel_time, 2),
            })
        except Exception as e:
            print(f"エラー: 観光地データが不正です: {spot} - {e}")

    return results

================
File: trareco_system/program/flask/README.md
================
# Trareco_System

# システムの流れ
1:  indexにアクセス
2:  観光地推薦ボタンを押す
3:  show_imageにリダイレクト
4:  画像を9枚表示
5:  画像を選択して送信ボタンを押す
6:  submit_selection_saveにリダイレクト
7:  選択回数をカウント
8:  選択回数が3になったらsubmit_selectionにリダイレクト（9毎の画像を選択する工程を3回行う）
9:  submit_selectionでDBに保存
10:  resultにリダイレクト
10:  resultで結果を表示

================
File: trareco_system/program/flask/server.py
================
from trarecoapp import app

if __name__ == '__main__':
    app.run()

================
File: trareco_system/SQL/CREATETABLE.sql
================
DROP TABLE IF EXISTS tourist_area;
CREATE TABLE tourist_area (
	tourist_id serial,
	path TEXT,
	area_name TEXT,
	longitude numeric(9,6),
	latitude numeric(9,6),
	season_id integer,
	timezone_id integer,
	category_id integer,
	crowding numeric,
	weather integer
	);

DROP TABLE IF EXISTS colorhistgram;
CREATE TABLE colorhistgram (
	tourist_id serial,
	red integer,
	orange integer,
	yellow integer,
	green integer,
	blue integer,
	indigo integer,
	purple integer,
	black integer,
	gray integer,
	white integer
	);
	
DROP TABLE IF EXISTS season;
CREATE TABLE season (
	season_id integer,
	season TEXT
	);

DROP TABLE IF EXISTS timezone;
CREATE TABLE timezone (
	timezone_id integer,
	timezone TEXT
	);
	
DROP TABLE IF EXISTS category;
CREATE TABLE category (
	category_id integer,
	category TEXT
	);

DROP TABLE IF EXISTS weather;
CREATE TABLE weather (
    weather_id	INT,
    weather	TEXT
);

DROP TABLE IF EXISTS color2imp;
CREATE TABLE color2imp (
	imp_id serial,
	imp_name TEXT,
	red integer,
	orange integer,
	yellow integer,
	green integer,
	blue integer,
	indigo integer,
	purple integer,
	black integer,
	gray integer,
	white integer
	);
	
DROP TABLE IF EXISTS imp_weight;
CREATE TABLE imp_weight (
	weight_id serial,
	season_spring real,
	season_summer real,
	season_fall real,
	season_winter real,
	time_morning2noon real,
	time_night real,
	category_mountain real,
	category_hotspring real,
	category_temple real
	);
	
	
DROP TABLE IF EXISTS return_tourist_area;
CREATE TABLE return_tourist_area (
	r_tourist_id serial,
	r_path TEXT,
	r_area_name TEXT,
	r_longitude numeric(9,6),
	r_latitude numeric(9,6),
	r_season_id integer,
	r_timezone_id integer,
	r_category_id integer,
	r_crowding numeric,
	r_weather integer
	);

DROP TABLE IF EXISTS return_colorhistgram;
CREATE TABLE return_colorhistgram (
	r_tourist_id serial,
	r_red integer,
	r_orange integer,
	r_yellow integer,
	r_green integer,
	r_blue integer,
	r_indigo integer,
	r_purple integer,
	r_black integer,
	r_gray integer,
	r_white integer
	);

================
File: trareco_system/SQL/INSERTINTO.sql
================
-- 感性推定のためにユーザに選んでもらう観光地情報
INSERT INTO tourist_area (path, area_name, longitude, latitude, season_id, timezone_id, category_id, crowding, weather) VALUES
	('山_1_冬_夜.jpg', '立山', '36.584550', '137.614098', '4', '2', '1', '0', '1'),
	('山_1_冬_昼.jpg', '立山', '36.584550', '137.614098', '4', '1', '1', '0', '2'),
	('山_1_夏_夜.jpg', '立山', '36.584550', '137.614098', '2', '2', '1', '0', '1'),
	('山_1_夏_昼.jpg', '立山', '36.584550', '137.614098', '2', '1', '1', '0', '2'),
	('山_1_春_夜.jpg', '立山', '36.584550', '137.614098', '1', '2', '1', '0', '1'),
	('山_1_春_昼.jpg', '立山', '36.584550', '137.614098', '1', '1', '1', '0', '2'),
	('山_1_秋_夜.jpg', '立山', '36.584550', '137.614098', '3', '2', '1', '0', '1'),
	('山_1_秋_昼.jpg', '立山', '36.584550', '137.614098', '3', '1', '1', '0', '1'),
	('山_2_冬_夜.jpg', '伊吹山', '35.419295', '136.406172', '4', '2', '1', '0', '1'),
	('山_2_冬_昼.jpg', '伊吹山', '35.419295', '136.406172', '4', '1', '1', '0.03', '2'),
	('山_2_夏_夜.jpg', '伊吹山', '35.419295', '136.406172', '2', '2', '1', '0', '1'),
	('山_2_夏_昼.jpg', '伊吹山', '35.419295', '136.406172', '2', '1', '1', '0', '2'),
	('山_2_春_夜.jpg', '伊吹山', '35.419295', '136.406172', '1', '2', '1', '0', '1'),
	('山_2_春_昼.jpg', '伊吹山', '35.419295', '136.406172', '1', '1', '1', '0', '1'),
	('山_2_秋_夜.jpg', '伊吹山', '35.419295', '136.406172', '3', '2', '1', '0', '1'),
	('山_2_秋_昼.jpg', '伊吹山', '35.419295', '136.406172', '3', '1', '1', '0', '2'),
	('温泉_1_冬_夜.jpg', '草津温泉', '36.683360', '138.555817', '4', '2', '2', '0.01', '1'),
	('温泉_1_冬_昼.jpg', '草津温泉', '36.683360', '138.555817', '4', '1', '2', '0', '1'),
	('温泉_1_夏_夜.jpg', '草津温泉', '36.683360', '138.555817', '2', '2', '2', '0', '1'),
	('温泉_1_夏_昼.jpg', '草津温泉', '36.683360', '138.555817', '2', '1', '2', '0', '1'),
	('温泉_1_春_夜.jpg', '草津温泉', '36.683360', '138.555817', '1', '2', '2', '0', '2'),
	('温泉_1_春_昼.jpg', '草津温泉', '36.683360', '138.555817', '1', '1', '2', '0', '1'),
	('温泉_1_秋_夜.jpg', '草津温泉', '36.683360', '138.555817', '3', '2', '2', '0', '1'),
	('温泉_1_秋_昼.jpg', '草津温泉', '36.683360', '138.555817', '3', '1', '2', '0', '1'),
	('温泉_2_冬_夜.jpg', '別府温泉', '33.297844', '131.484086', '4', '2', '2', '0', '1'),
	('温泉_2_冬_昼.jpg', '別府温泉', '33.297844', '131.484086', '4', '1', '2', '0', '1'),
	('温泉_2_夏_夜.jpg', '別府温泉', '33.297844', '131.484086', '2', '2', '2', '0', '2'),
	('温泉_2_夏_昼.jpg', '別府温泉', '33.297844', '131.484086', '2', '1', '2', '0', '1'),
	('温泉_2_春_夜.jpg', '別府温泉', '33.297844', '131.484086', '1', '2', '2', '0', '1'),
	('温泉_2_春_昼.jpg', '別府温泉', '33.297844', '131.484086', '1', '1', '2', '0', '1'),
	('温泉_2_秋_夜.jpg', '別府温泉', '33.297844', '131.484086', '3', '2', '2', '0', '2'),
	('温泉_2_秋_昼.jpg', '別府温泉', '33.297844', '131.484086', '3', '1', '2', '0.01', '2'),
	('神社_1_冬_夜.jpg', '伊勢神宮', '34.454992', '136.725447', '4', '2', '3', '0.02', '1'),
	('神社_1_冬_昼.jpg', '伊勢神宮', '34.454992', '136.725447', '4', '1', '3', '0', '4'),
	('神社_1_夏_夜.jpg', '伊勢神宮', '34.454992', '136.725447', '2', '2', '3', '0.05', '2'),
	('神社_1_夏_昼.jpg', '伊勢神宮', '34.454992', '136.725447', '2', '1', '3', '0.02', '1'),
	('神社_1_春_夜.jpg', '伊勢神宮', '34.454992', '136.725447', '1', '2', '3', '0.03', '1'),
	('神社_1_春_昼.jpg', '伊勢神宮', '34.454992', '136.725447', '1', '1', '3', '0', '2'),
	('神社_1_秋_夜.jpg', '伊勢神宮', '34.454992', '136.725447', '3', '2', '3', '0', '1'),
	('神社_1_秋_昼.jpg', '伊勢神宮', '34.454992', '136.725447', '3', '1', '3', '0', '2'),
	('神社_2_冬_夜.jpg', '金閣寺', '35.039628', '135.729288', '4', '2', '3', '0', '4'),
	('神社_2_冬_昼.jpg', '金閣寺', '35.039628', '135.729288', '4', '1', '3', '0', '1'),
	('神社_2_夏_夜.jpg', '金閣寺', '35.039628', '135.729288', '2', '2', '3', '0', '1'),
	('神社_2_夏_昼.jpg', '金閣寺', '35.039628', '135.729288', '2', '1', '3', '0', '2'),
	('神社_2_春_夜.jpg', '金閣寺', '35.039628', '135.729288', '1', '2', '3', '0', '1'),
	('神社_2_春_昼.jpg', '金閣寺', '35.039628', '135.729288', '1', '1', '3', '0', '1'),
	('神社_2_秋_夜.jpg', '金閣寺', '35.039628', '135.729288', '3', '2', '3', '0', '2'),
	('神社_2_秋_昼.jpg', '金閣寺', '35.039628', '135.729288', '3', '1', '3', '0', '2');
	
	
-- それぞれの観光地の色彩ヒストグラム
INSERT INTO colorhistgram (red, orange, yellow, green, blue, indigo, purple, black, gray, white) VALUES
	('0', '81', '0', '0', '2', '65421', '6312', '15086', '153063', '35'),
	('0', '132581', '0', '0', '0', '9686', '63012', '10330', '24073', '318'),
	('0', '54', '1', '0', '0', '2748', '278', '119065', '117839', '15'),
	('5174', '86853', '0', '0', '0', '9771', '11138', '8017', '93915', '25132'),
	('0', '0', '0', '0', '0', '1', '1', '233003', '6995', '0'),
	('0', '132581', '0', '0', '0', '9686', '63012', '10330', '24073', '318'),
	('367', '33275', '219', '3', '891', '20879', '69491', '59285', '53624', '1966'),
	('34107', '42221', '294', '0', '4334', '22183', '64074', '18994', '45066', '8727'),
	('0', '166', '0', '0', '0', '8477', '5166', '103846', '122345', '0'),
	('4', '174063', '0', '0', '1', '4758', '29293', '9055', '22623', '203'),
	('0', '4898', '0', '0', '0', '19842', '12154', '76547', '125726', '833'),
	('0', '39770', '111', '2', '187', '34581', '57620', '12286', '73135', '22308'),
	('0', '675', '23', '0', '0', '24261', '28667', '94537', '91597', '240'),
	('222', '118975', '0', '4', '39', '14115', '78216', '2472', '18691', '7266'),
	('0', '6', '0', '0', '0', '47454', '3934', '68564', '120040', '2'),
	('124241', '27490', '353', '15', '3500', '11873', '36474', '2346', '8875', '24833'),
	('1', '35027', '307', '0', '10201', '13536', '37517', '72977', '32146', '38288'),
	('0', '45903', '0', '0', '0', '45800', '82437', '8894', '48496', '8470'),
	('0', '13364', '0', '0', '40', '28901', '47021', '24298', '123169', '3207'),
	('3', '26548', '0', '0', '0', '19458', '43786', '87698', '59140', '3367'),
	('7', '11716', '5558', '1', '1362', '36715', '38151', '32129', '107109', '7252'),
	('0', '40306', '0', '0', '0', '22592', '62789', '39547', '63408', '11358'),
	('13910', '52229', '25', '0', '4696', '14566', '38134', '63013', '40164', '13263'),
	('183', '18767', '6', '0', '6051', '15218', '21651', '52386', '99268', '26470'),
	('0', '41583', '0', '0', '670', '19034', '32311', '60557', '67455', '18390'),
	('0', '41794', '0', '0', '0', '27207', '59218', '21404', '71759', '18618'),
	('802', '17313', '24', '29', '4170', '28769', '36757', '64541', '85431', '2164'),
	('0', '14691', '725', '0', '23', '30335', '38394', '62549', '89540', '3743'),
	('4', '10151', '2', '25', '400', '22560', '37630', '71264', '95289', '2675'),
	('0', '38970', '21', '0', '62', '17649', '48950', '68775', '57275', '8298'),
	('2861', '6314', '574', '0', '848', '12243', '10283', '66461', '117418', '22998'),
	('16', '49024', '93', '0', '777', '30257', '61163', '22481', '66059', '10130'),
	('0', '5044', '0', '0', '0', '6868', '11062', '178557', '36375', '2094'),
	('0', '93395', '0', '0', '0', '9625', '39203', '25441', '67893', '4443'),
	('3', '3049', '0', '0', '1424', '9012', '12282', '175312', '37798', '1120'),
	('0', '22134', '25', '0', '0', '19247', '32001', '67178', '88415', '11000'),
	('7', '16137', '0', '0', '2', '17808', '45145', '124208', '36115', '578'),
	('0', '74738', '0', '0', '0', '18455', '66766', '11328', '24425', '44288'),
	('119', '13661', '7114', '0', '893', '49645', '43781', '29501', '90540', '4746'),
	('0', '66576', '0', '0', '0', '19073', '74817', '30527', '47482', '1525'),
	('0', '13263', '0', '0', '0', '48790', '79500', '36204', '60386', '1857'),
	('6908', '43403', '0', '0', '307', '27641', '64436', '21361', '60109', '15835'),
	('0', '8564', '0', '0', '2', '3960', '11783', '202046', '13489', '156'),
	('0', '29817', '1', '0', '22', '20233', '23297', '46066', '89193', '31371'),
	('0', '11999', '0', '0', '0', '6627', '14848', '177598', '24866', '4062'),
	('0', '56449', '150', '0', '15', '23947', '58656', '16804', '80994', '2985'),
	('0', '5041', '10', '0', '173', '4770', '6670', '194061', '28679', '596'),
	('68', '48256', '3', '0', '991', '27932', '51367', '16366', '79450', '15567');

-- 観光地の季節
INSERT INTO season (season_id, season) 
VALUES
(1, '春'),
(2, '夏'),
(3, '秋'),
(4, '冬');

-- 観光地の時間帯
INSERT INTO timezone (timezone_id, timezone) 
VALUES
(1, '朝昼'),
(2, '夜');

-- 観光地のカテゴリー
INSERT INTO category (category_id, category) 
VALUES
(1, '山'),
(2, '温泉'),
(3, '神社');

-- 天気
INSERT INTO weather (weather_id, weather) VALUES
	('1', '晴'),
	('2', '曇'),
	('3', '雨'),
	('4', '雪');

-- 感性語と色彩の対応表
INSERT INTO color2imp (imp_name, red, orange, yellow, green, blue, indigo, purple, black, gray, white) VALUES
	('楽しい', '8', '10', '9', '6', '5', '3', '4', '1', '2', '7'),
	('賑やかな', '10', '9', '8', '3', '5', '4', '6', '1', '2', '7'),
	('ゆっくり', '1', '2', '3', '10', '9', '5', '4', '6', '7', '8'),
	('気が晴れる', '4', '5', '6', '10', '8', '7', '3', '1', '2', '9'),
	('面白い', '8', '10', '9', '1', '2', '3', '6', '4', '5', '7'),
	('わいわい', '8', '9', '10', '4', '5', '3', '6', '1', '2', '7'),
	('はしゃぐ', '6', '8', '7', '3', '5', '2', '9', '1', '4', '10'),
	('のんびり', '1', '3', '2', '10', '9', '8', '4', '7', '6', '5'),
	('うきうき', '7', '10', '9', '1', '6', '2', '8', '3', '4', '5'),
	('落ち着いた', '1', '5', '3', '7', '6', '4', '2', '8', '10', '9'),
	('田舎', '1', '2', '3', '10', '9', '5', '4', '6', '7', '8'),
	('わくわく', '10', '9', '8', '1', '3', '2', '7', '4', '5', '6'),
	('きれい', '1', '8', '2', '10', '9', '5', '6', '4', '3', '7'),
	('癒される', '1', '2', '3', '9', '10', '7', '4', '6', '5', '8'),
	('まったり', '1', '2', '3', '10', '4', '5', '6', '9', '8', '7');
	


-- その他の感性による重みづけ
INSERT INTO imp_weight (season_spring, season_summer, season_fall, season_winter, time_morning2noon, time_night, category_mountain, category_hotspring, category_temple) VALUES
	('1', '2', '1', '1', '2', '1', '1', '2', '1'),
	('2', '2', '1', '1', '2', '1', '1', '2', '1'),
	('1', '1', '2', '2', '1', '2', '2', '1', '2'),
	('1', '1', '1', '1', '2', '1', '2', '1', '1'),
	('1', '2', '1', '1', '2', '1', '1', '2', '1'),
	('1', '2', '1', '1', '1', '1', '1', '2', '1'),
	('1', '1', '1', '1', '2', '1', '1', '2', '1'),
	('1', '1', '2', '1', '1', '2', '2', '2', '1'),
	('2', '1', '1', '1', '2', '1', '1', '2', '1'),
	('1', '1', '2', '2', '1', '2', '2', '1', '2'),
	('1', '1', '2', '2', '1', '1', '1', '1', '2'),
	('2', '1', '1', '1', '2', '1', '2', '1', '1'),
	('2', '1', '2', '2', '1', '1', '2', '1', '1'),
	('1', '1', '2', '1', '1', '1', '2', '2', '1'),
	('1', '1', '2', '2', '1', '1', '1', '2', '1');

-- 推薦用の観光地情報
INSERT INTO return_tourist_area (r_path, r_area_name, r_longitude, r_latitude, r_season_id, r_timezone_id, r_category_id, r_crowding, r_weather) VALUES
	('下呂温泉.jpg', '下呂温泉', '35.361393', '138.727191', '1', '2', '2', '0', '1'),
	('道後温泉.jpg', '道後温泉', '35.714875', '139.796507', '3', '2', '2', '0', '2'),
	('厳島神社.jpg', '厳島神社', '36.226062', '140.106977', '4', '1', '3', '0', '1'),
	('浅草寺.jpg', '浅草寺', '33.852041', '132.786631', '4', '2', '3', '0', '1'),
	('富士山.jpg', '富士山', '35.809520', '137.238344', '4', '1', '1', '0', '1'),
	('筑波山.jpg', '筑波山', '34.332482', '132.351163', '2', '1', '1', '0.05', '1');

-- 推薦用の観光地情報の色彩ヒストグラム
INSERT INTO return_colorhistgram (r_red, r_orange, r_yellow, r_green, r_blue, r_indigo, r_purple, r_black, r_gray, r_white) VALUES
	('1', '10067', '17', '2', '227', '21129', '38863', '81402', '87402', '890'),
	('195', '20310', '566', '15', '6804', '23618', '68042', '52934', '67087', '429'),
	('5', '80319', '0', '0', '804', '19414', '93101', '1826', '24299', '20232'),
	('1664', '14127', '2', '0', '174', '7676', '15005', '176248', '22970', '2134'),
	('0', '136404', '0', '0', '0', '34568', '61994', '1167', '4618', '1249'),
	('0', '102385', '1', '0', '0', '23994', '44299', '1833', '66429', '1059');

================
File: trareco_system/.python-version
================
3.11.3

================
File: .gitignore
================
*.pyc
.venv/
flask_session/
__pycache__/
*.dylib

================
File: README.md
================
# trareco_app2024
